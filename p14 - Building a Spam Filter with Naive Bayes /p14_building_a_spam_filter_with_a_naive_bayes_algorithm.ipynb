{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building A Spam Filter With Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This project aims at creating a spam filter that resorts to a multinomial Naive Bayes algorithm in order to distinguish spam messages from regular ones. The filter will be tested on a data set comprised of 5572 messages that have been previously determined by humans as spam or not spam.\n",
    "\n",
    "The spam filter is considered to be successful if it can filter out 80% of the spam from a test set.\n",
    "\n",
    "The working data set has been made available by Tiago A. Almeida and José María Gómez Hidalgo, and is publicly available at the [The UCI Machine Learning](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Set and the Algorithm's Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_spam_full = pd.read_csv('SMSSpamCollection.txt',\n",
    "                   sep='\\t',\n",
    "                   names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Label   5572 non-null   object\n",
      " 1   SMS     5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sms_spam_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Label` column is binary, the values are:\n",
    "\n",
    "- `spam`\n",
    "- `ham` (not spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are depicted the first five messages in the data set, so that one can observe the general writing style (expected to be informal), and how this can be taken into consideration when formulating the spam filtering tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                                                                           SMS  \n",
       "0                                              Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...  \n",
       "1                                                                                                                                Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's  \n",
       "3                                                                                                            U dun say so early hor... U c already then say...  \n",
       "4                                                                                                Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "sms_spam_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we can see that only aprox. 13.4% of the messages are spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.6\n",
       "spam    13.4\n",
       "Name: ham vs spam (%), dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_label = sms_spam_full.Label.value_counts(normalize=True).round(3)*100\n",
    "\n",
    "count_label = count_label.rename('ham vs spam (%)')\n",
    "\n",
    "count_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The process to build the spam filter will take 3 steps:\n",
    "\n",
    "\n",
    "1. Write a script that takes a pre-evaluated data set of messages (training set) and instruct it to learn how humans classify messages.\n",
    "\n",
    "\n",
    "2. Use the knowledge acquired in 1. to estimate probabilities for new messages — probabilities for spam and non-spam.\n",
    "\n",
    "\n",
    "3. Classify a new message based on these probability values — if the probability for spam is greater, then it classifies the message as spam; otherwise, it classifies it as non-spam (if the two probability values are equal, then we may need a human to classify the message)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step  1: creating a training set and a test set \n",
    "\n",
    "1. Randomize the original data set - `sms_spam_full`.\n",
    "\n",
    "\n",
    "2. Split the randomized data set, into a training set (20%) and a testing set (remaining 80%).\n",
    "\n",
    "\n",
    "3. Compare the `Label` value frequency distribution of the entire randomized DataFrame with the previously made subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Randomize.\n",
    "random_sms_spam = sms_spam_full.sample(n=None, frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From earlier on we know that `random_sms_spam` has 5572 entries (0 to 5571)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of messages/rows in random_sms_spam: 5572 \n",
      "80% of total messages/rows in random_sms_spam: 4458.0\n"
     ]
    }
   ],
   "source": [
    "eighty_perc = random_sms_spam.shape[0] * 0.8\n",
    "\n",
    "print(f'Total number of messages/rows in random_sms_spam: {random_sms_spam.shape[0]}', \n",
    "      f'\\n80% of total messages/rows in random_sms_spam: {round(eighty_perc, 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the information above we set the training set as the rows 0 to 4458, 80% of the total rows in `random_sms_spam`. The remaining rows, will form the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split the randomized data set.\n",
    "training_set = random_sms_spam.copy().iloc[:4458+1, :]\n",
    "\n",
    "testing_set = random_sms_spam.copy().iloc[4458:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, comparing the distribution of values in the `Label` column across DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_sms_spam</th>\n",
       "      <th>count_label_training</th>\n",
       "      <th>count_label_testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>86.6</td>\n",
       "      <td>86.5</td>\n",
       "      <td>86.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>13.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      random_sms_spam  count_label_training  count_label_testing\n",
       "ham              86.6                  86.5                 86.8\n",
       "spam             13.4                  13.5                 13.2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Compare spam value across DataFrames.\n",
    "\n",
    "# Training set.\n",
    "count_label_training = training_set.Label.value_counts(normalize=True).round(3)*100\n",
    "\n",
    "count_label_training = count_label_training.rename('ham vs spam (%)')\n",
    "\n",
    "# Testing set.\n",
    "count_label_testing = testing_set.Label.value_counts(normalize=True).round(3)*100\n",
    "\n",
    "count_label_testing = count_label_testing.rename('ham vs spam (%)')\n",
    "\n",
    "\n",
    "# Combining all label percentage counts for comparison.\n",
    "compare_label = pd.DataFrame({'random_sms_spam': count_label,\n",
    "                              'count_label_training': count_label_training,\n",
    "                              'count_label_testing': count_label_testing})\n",
    "\n",
    "compare_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the table above, the value distribution is very similar across the panel, meaning that we can infer the conclusions produced from the training set to the testing set, since both sets resemble the original series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving RAM 1\n",
    "del sms_spam_full\n",
    "del random_sms_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: use the training set to teach the algorithm to classify new messages\n",
    "---\n",
    "When a new message arrives and is used as input the Naive Bayes algorithm will make the classification based on the results it gets from these two equations (\"$Spam^C$\" and \"$Ham$\" can be used interchangeably in this case):\n",
    "\n",
    "\n",
    "$P(Ham|w_1, w_2, ..., w_n) > P(Spam|w_1, w_2, ..., w_n)$\n",
    "\n",
    "Building a Naive Bayes algorithm entails two further intertwined steps. The final goal is two take a random new message as input, compute and compare the equations below:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}\n",
    "\n",
    "- If $P(Ham|w_1, w_2, ..., w_n) > P(Spam|w_1, w_2, ..., w_n)$, then the message is classified as ham.\n",
    "\n",
    "\n",
    "- If $P(Ham|w_1, w_2, ..., w_n) < P(Spam|w_1, w_2, ..., w_n)$, then the message is classified as spam.\n",
    "\n",
    "\n",
    "- If $P(Ham|w_1, w_2, ..., w_n) = P(Spam|w_1, w_2, ..., w_n)$, then the algorithm must request human help.\n",
    "\n",
    "To calculate $P(w_i|Spam)$ and $P(w_i|Ham)$ inside the formulas above, we need to calculate the two equations below, which read: 'the probability of a message that contains the word $w_i$ to be spam is...' and 'the probability of a message that contains the (same) word $w_i$ to be non spam is...', respectively. \n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "Here is where the training test enters as an input because we compute $P(w_i|Spam)$ and $P(w_i|Ham)$ based on elements taken and reformulated from this data set and then apply that to calculate $P(Spam | w_1,w_2, ..., w_n)$ and $P(Ham | w_1,w_2, ..., w_n)$. In other words, the Step 2 of the process is to create a 'blueprint' data set that allows us to compute\n",
    "$P(w_i|Spam)$ and $P(w_i|Ham)$ for every word of every message in the training data set, from which we pick up the probabilities associated with the words that are contained in a message, that we wish to filter out.\n",
    "\n",
    "A mock example: \n",
    "\n",
    "We want to calculate this message probability of being spam: 'go crazy'.\n",
    "\n",
    "The probabilities in the 'blueprints' can be calculated because the word 'go' can be found in 667 normal messages and in 39 spam messages, while 'crazy' can be found in 8 normal messages and in 1 spam message (messages within the training set). \n",
    "\n",
    "The blueprints data sets can then be filled out:\n",
    "\n",
    "- Probability of spam given the targeted words:\n",
    "    - $P('go'|Spam) = a$\n",
    "    - $P('crazy'|Spam) = b$\n",
    "\n",
    "\n",
    "- Probability of spam given the targeted words:\n",
    "    - $P('go'|Ham) = c$\n",
    "    - $P('crazy'|Ham) = d$\n",
    "\n",
    "\n",
    "Which allow us to calculate:\n",
    "\n",
    "$P(Spam | w_1, w_2) = a * b$\n",
    "\n",
    "$P(Ham | w_1, w_2) = c *d$\n",
    "\n",
    "Having this information, we can compare values and determine if 'go crazy' is more likely to be, and ultimately categorized as spam or not spam.\n",
    "We can also notice that if a test message has a word which is not in the blueprint, because it wasn't included in the training set to begin with, it will not be considered in the filter, since we don't specify a way to calculate a probability for it. \n",
    "\n",
    "Let's also summarize what the terms in the equations above mean. Recall that all of this elements will be taken from the training set.\n",
    "\n",
    "\\begin{align}\n",
    "&N_{w_i|Spam} = \\text{the number of times the word } w_i \\text{ occurs in spam messages} \\\\\n",
    "&N_{w_i|Spam^C} = \\text{the number of times the word } w_i \\text{ occurs in non-spam messages} \\\\\n",
    "\\\\\n",
    "&N_{Spam} = \\text{total number of words in spam messages} \\\\\n",
    "&N_{Spam^C} = \\text{total number of words in non-spam messages} \\\\\n",
    "\\\\\n",
    "&N_{Vocabulary} = \\text{total number of words in the vocabulary} \\\\\n",
    "&\\alpha = 1 \\ \\ \\ \\ (\\alpha \\text{ is a smoothing parameter})\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Message cleaning.\n",
    "\n",
    "\n",
    "Prior to building the 'blueprint' for the probabilities we must clean the messages in the `training_set`:\n",
    "\n",
    "- eliminate punctuation.\n",
    "- lower case every word.\n",
    "- remove whitespaces at end and beginning of the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating punctuation.\n",
    "cleaned = training_set.SMS.copy().str.replace('\\W', ' ', regex=True) \n",
    "\n",
    "# `{2.,}` ensures that if there are two or more joined whitespaces they are converted to just one.\n",
    "cleaned = cleaned.str.replace(' {2,}', ' ', regex=True) \n",
    "\n",
    "# Remove whitespaces.\n",
    "cleaned = cleaned.str.replace('(\\A +| +\\Z)', '', regex=True)\n",
    "\n",
    "# Lower case for every string.\n",
    "cleaned = cleaned.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking changes in `cleaned`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                             yep by the pretty sculpture\n",
       "1                                                              yes princess are you going to make me moan\n",
       "2                                                                              welp apparently he retired\n",
       "3                                                                                                  havent\n",
       "4    i forgot 2 ask ü all smth there s a card on da present lei how ü all want 2 write smth or sign on it\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Producing a 'vocabulary' .\n",
    "\n",
    "\n",
    "The next stage entails the production of a vocabulary (array of unique words taken from every message in `cleaned`), with the following steps:\n",
    "\n",
    "1. split each message into a list of words.\n",
    "2. create an empty set of unique words.\n",
    "3. add words to the set.\n",
    "4. convert set into back into a (sorted) list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "cleaned_split = cleaned.str.split(' ', expand=False) \n",
    "\n",
    "# 2.\n",
    "vocabulary = set()\n",
    "\n",
    "# 3.\n",
    "for index, sms in enumerate(cleaned_split):\n",
    "    for word in sms:\n",
    "        if word:\n",
    "            vocabulary.add(word)              \n",
    "            \n",
    "# 4.\n",
    "vocabulary = sorted(list(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Producing a word counter DataFrame.\n",
    "\n",
    "\n",
    "To continue the task of organizing the elements required to compute $P(w_i|Spam)$ and $P(w_i|Ham)$ for each word in the _vocabulary_, we opt to build a data set that registers how many times each word occurs in each message. To do this, we can collect this information by first compiling a dictionary and then convert it into a DataFrame, for ease of read and access.\n",
    "\n",
    "\n",
    "\n",
    "Both the dictionary and DataFrame display the data similarly: we must be able to choose a word that is represented by a key and a column, respectively, and be able to check the word frequency by message/row (in the dictionary each message is given by the index position in the list for every key/word). \n",
    "\n",
    "\n",
    "Before that we refine a little further the cleaning of messages:\n",
    "- Rows 1098 and 2700 are messages that only contain emojis, therefore they can be dropped out of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098 ['']\n",
      "2700 ['']\n",
      "\n",
      "Messages containing only Emojis:\n",
      "\n",
      "Label    ham\n",
      "SMS      :) \n",
      "Name: 1098, dtype: object \n",
      "\n",
      "Label        ham\n",
      "SMS      :-) :-)\n",
      "Name: 2700, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for index, value in enumerate(cleaned_split):\n",
    "    if '' in value:\n",
    "        print(index, value)\n",
    "\n",
    "print('\\nMessages containing only Emojis:\\n')       \n",
    "print(training_set.iloc[1098,:],'\\n')\n",
    "print(training_set.iloc[2700,:])\n",
    "\n",
    "cleaned_split = cleaned_split.drop([1098, 2700])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Filling out the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(cleaned_split) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(cleaned_split):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hows does the dictionary looks like and how to read it:\n",
    "\n",
    "- We are looking at five random keys/unique words in the dictionary. Each index position of these lists represents one message, identical to the row index in `training_set`. Here we limited the search to the first 10 messages. Looking at this sample, we notice that none of these messages contains any of the following random words taken from the `vocabulary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: \"dog\". Counts: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Word: \"answer\". Counts: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Word: \"wow\". Counts: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Word: \"drink\". Counts: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Word: \"night\". Counts: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for key in ['dog', 'answer', 'wow', 'drink', 'night']:\n",
    "    print(f'Word: \"{key}\". Counts: {word_counts_per_sms[key][:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Convert dictionary into DataFrame.\n",
    "word_counts_per_sms_df = pd.DataFrame(word_counts_per_sms)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing if the conversion was successful: using the same example above, we can see that words are now column labels, whilst each message is represented by the (row) index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog</th>\n",
       "      <th>answer</th>\n",
       "      <th>wow</th>\n",
       "      <th>drink</th>\n",
       "      <th>night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dog  answer  wow  drink  night\n",
       "0     0       0    0      0      0\n",
       "1     0       0    0      0      0\n",
       "2     0       0    0      0      0\n",
       "3     0       0    0      0      0\n",
       "4     0       0    0      0      0\n",
       "5     0       0    0      0      0\n",
       "6     0       0    0      0      0\n",
       "7     0       0    0      0      0\n",
       "8     0       0    0      0      0\n",
       "9     0       0    0      0      0\n",
       "10    0       0    0      0      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_sms_df.loc[:10, ['dog', 'answer', 'wow', 'drink', 'night']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, concatenating `training_set` with `word_counts_per_sms_df` into a new DataFrame - `training_set_2`, in order to make it easier to look up for the original messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_cols = list(training_set.columns) + list(word_counts_per_sms_df.columns)\n",
    "\n",
    "training_set_2 = word_counts_per_sms_df.merge(training_set, left_index=True, right_index=True)\n",
    "\n",
    "training_set_2  = training_set_2.reindex(columns=ordered_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First two rows on `training_set_2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            SMS  0  00  000  000pes  \\\n",
       "0   ham                   Yep, by the pretty sculpture  0   0    0       0   \n",
       "1   ham  Yes, princess. Are you going to make me moan?  0   0    0       0   \n",
       "\n",
       "   008704050406  0089  01223585334  02  \n",
       "0             0     0            0   0  \n",
       "1             0     0            0   0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_2.iloc[:2, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing whether the rows in `training_set_2` were well aligned with the correspondent rows in `word_counts_per_sms_df` with two examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1: row 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set_2[\"SMS\"], row 0: Yep, by the pretty sculpture\n",
      "\n",
      "\n",
      "training_set_2, row 0 - columns that are \">0\":\n",
      "\n",
      "by           1\n",
      "pretty       1\n",
      "sculpture    1\n",
      "the          1\n",
      "yep          1\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cond_row_0 = training_set_2.iloc[0, 2:] == 1 \n",
    "\n",
    "print(f'training_set_2[\"SMS\"], row 0: {training_set_2.iloc[0, 1]}')\n",
    "print('\\n')\n",
    "print(f'training_set_2, row 0 - columns that are \">0\":\\n\\n{training_set_2.iloc[0, 2:][cond_row_0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2: row 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, princess. Are you going to make me moan?\n",
      "\n",
      "\n",
      "are         1\n",
      "going       1\n",
      "make        1\n",
      "me          1\n",
      "moan        1\n",
      "princess    1\n",
      "to          1\n",
      "yes         1\n",
      "you         1\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cond_row_1 = training_set_2.iloc[1, 2:] == 1 \n",
    "\n",
    "print(training_set_2.iloc[1, 1])\n",
    "print('\\n')\n",
    "print(training_set_2.iloc[1, 2:][cond_row_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free RAM 2\n",
    "del word_counts_per_sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the elements within the Naive Bayes algorithm:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Starting with:\n",
    "\n",
    "- $P(Spam)$ and $P(Ham)$.\n",
    "- $N_{Spam}$, $N_{Ham}$, $N_{Vocabulary}$\n",
    "\n",
    "The Laplace smoothing parameter is set to 1: $α=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of Spam and Ham are just the proportion of each from the total number of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam) = 0.13461969934933812\n",
      "P(Ham) = 0.8653803006506618\n"
     ]
    }
   ],
   "source": [
    "label_counts_ts2 = training_set_2.Label.value_counts(normalize=True)\n",
    "\n",
    "p_spam = label_counts_ts2.spam\n",
    "\n",
    "p_ham = label_counts_ts2.ham\n",
    "\n",
    "print(f'P(Spam) = {p_spam}')\n",
    "print(f'P(Ham) = {p_ham}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting $N_{Spam}$, $N_{Ham}$, $N_{Vocabulary}$.\n",
    "\n",
    "- $N_{Vocabulary}$ is given by the number of words in the `vocabulary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_vocabulary = 7785\n"
     ]
    }
   ],
   "source": [
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "print(f'N_vocabulary = {n_vocabulary}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum up the total number of words for spam messages and for non-spam messages - $N_{Spam}$, $N_{Ham}$ respectively, the procedure will be the following:\n",
    "\n",
    "1. create two DataFrames that only contain either spam or non-spam messages.\n",
    "\n",
    "2. in the same line of code, sum up all values by row (creating a Series of summed values) and then sum up all those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_spam: 11207 \n",
      "n_ham: 61228\n"
     ]
    }
   ],
   "source": [
    "sms_spam = training_set_2.iloc[:, 2:-1].copy()[training_set_2.Label=='spam']\n",
    "\n",
    "sms_ham = training_set_2.iloc[:, 2:-1].copy()[training_set_2.Label=='ham']\n",
    "\n",
    "n_spam = sms_spam.sum(axis=1).sum()\n",
    "n_ham = sms_ham.sum(axis=1).sum()\n",
    "\n",
    "print(f'n_spam: {n_spam}',\n",
    "     f'\\nn_ham: {n_ham}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last elements of $P(w_i|Spam)$ and $P(w_i|Ham)$ that have yet to be calculated are:\n",
    "\n",
    "\\begin{align}\n",
    "&N_{w_i|Spam} = \\text{the number of times the word } w_i \\text{ occurs in spam messages} \\\\\n",
    "&N_{w_i|Spam^C} = \\text{the number of times the word } w_i \\text{ occurs in non-spam messages} \\\\\n",
    "\\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "In order to find these values we can resort again to `sms_spam` and `sms_ham`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_spam_sum = sms_spam.sum().transpose()\n",
    "\n",
    "sms_ham_sum = sms_ham.sum().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                1\n",
       "00               7\n",
       "000              6\n",
       "000pes           0\n",
       "008704050406     1\n",
       "                ..\n",
       "zyada            0\n",
       "é                0\n",
       "ú1               1\n",
       "ü               15\n",
       "〨ud              0\n",
       "Length: 7784, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam_sum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can locate how many times a given word appears in either spam or ham messages. An example: find those values for the word 'crazy'. We can see below that this word appears 9 times in normal messages and twice in spam messages (we count repeats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam_sum['crazy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_ham_sum['crazy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arriving at the 'blueprints' \n",
    "\n",
    "The last step before building the final spam filter is to fill out two dictionaries, that store $P(w_i|Spam)$ and $P(w_i|Ham)$ for each word in the _vocabulary_, based on the elements already collected:\n",
    "\n",
    "\n",
    "- `n_spam` and `n_ham`.\n",
    "- `n_vocabulary`.\n",
    "- $N_{w_i|Spam}$ and $N_{w_i|Ham}$.\n",
    "- `alpha`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wi_given_spam_dict = {}\n",
    "\n",
    "p_wi_given_ham_dict = {}\n",
    "\n",
    "alpha = 1\n",
    "\n",
    "# P(w_i|Spam)\n",
    "for i in range(0, sms_spam_sum.size):\n",
    "    index = sms_spam_sum.index[i] # stores each unique word\n",
    "    dividend = sms_spam_sum[index] + alpha\n",
    "    divisor = n_spam + (alpha*n_vocabulary)\n",
    "    p_wi_given_spam_dict[index] =  dividend / divisor\n",
    "\n",
    "    \n",
    "# P(w_i|Ham)\n",
    "for i in range(0, sms_ham_sum.size):\n",
    "    index = sms_ham_sum.index[i] # stores each unique word\n",
    "    dividend = sms_ham_sum[index] + alpha\n",
    "    divisor = n_ham + (alpha*n_vocabulary)\n",
    "    p_wi_given_ham_dict[index] =  dividend / divisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking first 5 items in `p_wi_given_spam_dict` and `p_wi_given_ham_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 0.00010530749789385004),\n",
       " ('00', 0.00042122999157540015),\n",
       " ('000', 0.00036857624262847516),\n",
       " ('000pes', 5.265374894692502e-05),\n",
       " ('008704050406', 0.00010530749789385004)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(p_wi_given_spam_dict.items())[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 4.3470070856215496e-05),\n",
       " ('00', 4.3470070856215496e-05),\n",
       " ('000', 0.00028980047237477),\n",
       " ('000pes', 2.8980047237477e-05),\n",
       " ('008704050406', 1.44900236187385e-05)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(p_wi_given_ham_dict.items())[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free RAM 3\n",
    "del sms_spam\n",
    "del sms_ham"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting Up All The Parts Together - Assembling The Spam Filter And Assessing Its Effectiveness\n",
    "\n",
    "---\n",
    "\n",
    "Now that $P(w_i|Spam)$ and $P(w_i|Ham)$ have been calculated throughout the entire span of messages contained in the training set, it is possible to finally build the spam filter by calculating and comparing $P(Spam|w_1, w_2, ..., w_n)$ with $P(Ham|w_1, w_2, ..., w_n)$. If by chance the values calculated for these probabilities are equal, no classification is made, and the function returns a string message asking for a human classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    \"\"\"Takes in a string - a cellphone message (SMS), and returns a classification of whether \n",
    "    the message is spam, not spam (ham), or if a human is required to classify the message.\n",
    "    \"\"\"\n",
    "\n",
    "    message = re.sub('\\W', ' ', message) # still a string\n",
    "    message = message.lower() # still a string\n",
    "    message = message.split() # now a list of strings\n",
    "\n",
    "    \n",
    "    # Calculating P(Spam|w_1, w_2, ..., w_n) with P(Ham|w_1, w_2, ..., w_n).\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # Note: if `word` is not in the spam or in the non-spam DataFrames the loop does nothing by default.\n",
    "    for word in message:\n",
    "        \n",
    "        if word in p_wi_given_spam_dict.keys():\n",
    "            p_spam_given_message *= p_wi_given_spam_dict[word]\n",
    "            \n",
    "        if word in p_wi_given_ham_dict.keys():\n",
    "            p_ham_given_message *= p_wi_given_ham_dict[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'Requires human classification.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are all set to apply the filter to every message on the `testing_set`. We register if the filter was successful in classifying each message correctly by comparing it with the classification in the `Label` column. We store these results in a column named `Correct` where '1' means well classified, and '0' wrongly classified. This will allow to easily calculate the accuracy rate of the filter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set['Test'] = testing_set['SMS'].apply(classify_test_set)\n",
    "\n",
    "\n",
    "# Assigns True if condition is met and multplying by one converts True in '1' and False in '0'.\n",
    "testing_set['Correct'] = (testing_set['Label'] == testing_set['Test'])*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Test</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Orange camera/video phones for FREE. Save £s with Free texts/weekend calls. Text YES for a callback orno to opt out</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult to type</td>\n",
       "      <td>ham</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega shop in asda counts as celebration but thats what i'm doing!</td>\n",
       "      <td>ham</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label  \\\n",
       "4458   ham   \n",
       "4459   ham   \n",
       "4460  spam   \n",
       "4461   ham   \n",
       "4462   ham   \n",
       "\n",
       "                                                                                                                                                                SMS  \\\n",
       "4458                                                                                                                      Later i guess. I needa do mcat study too.   \n",
       "4459                                                                                                                         But i haf enuff space got like 4 mb...   \n",
       "4460  Had your mobile 10 mths? Update to latest Orange camera/video phones for FREE. Save £s with Free texts/weekend calls. Text YES for a callback orno to opt out   \n",
       "4461                                                                                                          All sounds good. Fingers . Makes it difficult to type   \n",
       "4462                                                       All done, all handed in. Don't know if mega shop in asda counts as celebration but thats what i'm doing!   \n",
       "\n",
       "      Test  Correct  \n",
       "4458   ham        1  \n",
       "4459   ham        1  \n",
       "4460  spam        1  \n",
       "4461   ham        1  \n",
       "4462   ham        1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of well classified messages when using the `classify_test_set()` function/filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When applied to the messages in the `testing_set` (1114 entries) the test accuracy was aprox. 94.25%.\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = (testing_set['Correct'].sum() / testing_set.shape[0])*100\n",
    "\n",
    "test_accuracy = test_accuracy.round(2)\n",
    "\n",
    "print(f'When applied to the messages in the `testing_set` ({testing_set.shape[0]} entries) the test accuracy was aprox. {test_accuracy}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the value of the test accuracy of 98.74%, we can classify it as a success, since it exceeded the approval threshold of 80% by a substantial margin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Task\n",
    "\n",
    "### Isolate the 14 messages that were classified incorrectly and try to figure out why the algorithm reached the wrong conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, lets observe closer the 14 messages that were incorrectly tagged. For that purpose we isolate those messages into a separate DataFrame (`incorrect`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_incorrect = testing_set.Correct == 0\n",
    "\n",
    "incorrect = testing_set[cond_incorrect].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic info on `incorrect`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64 entries, 0 to 63\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Label    64 non-null     object\n",
      " 1   SMS      64 non-null     object\n",
      " 2   Test     64 non-null     object\n",
      " 3   Correct  64 non-null     int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "incorrect.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>25p 4 alfie Moon's Children in need song on ur mob. Tell ur m8s. Txt Tone charity to 8007 for Nokias or Poly charity for polys: zed 08701417012 profit 2 charity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg: Hey - I'm Buffy. 25 and love to satisfy men. Home alone feeling randy. Reply 2 C my PIX! QlynnBV Help08700621170150p a msg Send stop to stop txts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>As one of our registered subscribers u can enter the draw 4 a 100 G.B. gift voucher by replying with ENTER. To unsubscribe text STOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>goldviking (29/M) is inviting you to be his friend. Reply YES-762 or NO-762 See him: www.SMS.ac/u/goldviking STOP? Send STOP FRND to 62468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I wnt to buy a BMW car urgently..its vry urgent.but hv a shortage of  &amp;lt;#&amp;gt; Lacs.there is no source to arng dis amt. &amp;lt;#&amp;gt; lacs..thats my prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>spam</td>\n",
       "      <td>A link to your picture has been sent. You can also use http://alto18.co.uk/wave/wave.asp?o=44345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>spam</td>\n",
       "      <td>Please call our customer service representative on 0800 169 6031 between 10am-9pm as you have WON a guaranteed £1000 cash or £5000 prize!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg:Feelin kinda lnly hope u like 2 keep me company! Jst got a cam moby wanna c my pic?Txt or reply DATE to 82242 Msg150p 2rcv Hlp 08712317606 stop to 82242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here&gt;&gt; http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>spam</td>\n",
       "      <td>Text &amp; meet someone sexy today. U can find a date or even flirt its up to U. Join 4 just 10p. REPLY with NAME &amp; AGE eg Sam 25. 18 -msg recd@thirtyeight pence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  \\\n",
       "0   spam   \n",
       "1   spam   \n",
       "2   spam   \n",
       "3   spam   \n",
       "4    ham   \n",
       "..   ...   \n",
       "59  spam   \n",
       "60  spam   \n",
       "61  spam   \n",
       "62  spam   \n",
       "63  spam   \n",
       "\n",
       "                                                                                                                                                                  SMS  \n",
       "0   25p 4 alfie Moon's Children in need song on ur mob. Tell ur m8s. Txt Tone charity to 8007 for Nokias or Poly charity for polys: zed 08701417012 profit 2 charity.  \n",
       "1          FreeMsg: Hey - I'm Buffy. 25 and love to satisfy men. Home alone feeling randy. Reply 2 C my PIX! QlynnBV Help08700621170150p a msg Send stop to stop txts  \n",
       "2                                As one of our registered subscribers u can enter the draw 4 a 100 G.B. gift voucher by replying with ENTER. To unsubscribe text STOP  \n",
       "3                          goldviking (29/M) is inviting you to be his friend. Reply YES-762 or NO-762 See him: www.SMS.ac/u/goldviking STOP? Send STOP FRND to 62468  \n",
       "4              I wnt to buy a BMW car urgently..its vry urgent.but hv a shortage of  &lt;#&gt; Lacs.there is no source to arng dis amt. &lt;#&gt; lacs..thats my prob  \n",
       "..                                                                                                                                                                ...  \n",
       "59                                                                   A link to your picture has been sent. You can also use http://alto18.co.uk/wave/wave.asp?o=44345  \n",
       "60                          Please call our customer service representative on 0800 169 6031 between 10am-9pm as you have WON a guaranteed £1000 cash or £5000 prize!  \n",
       "61   FreeMsg:Feelin kinda lnly hope u like 2 keep me company! Jst got a cam moby wanna c my pic?Txt or reply DATE to 82242 Msg150p 2rcv Hlp 08712317606 stop to 82242  \n",
       "62              XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL  \n",
       "63      Text & meet someone sexy today. U can find a date or even flirt its up to U. Join 4 just 10p. REPLY with NAME & AGE eg Sam 25. 18 -msg recd@thirtyeight pence  \n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect[['Label', 'SMS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we can read above, we must first acknowledge that some messages are too ambiguous and difficult to pronounce correctly as spam or not spam, even when resorting to human judgment, some examples: \n",
    "\n",
    "- 'Unlimited texts. Limited minutes.' (row 2).\n",
    "- 'We have sent JD for Customer Service cum Accounts Executive to ur mail id, For details contact us' (row 7).\n",
    "- 'RCT' THNQ Adrian for U text. Rgds Vatian' (row 11).\n",
    "\n",
    "One thing we can observe in `incorrect` is that there are spam messages that have implicit references to money or currency symbols like '£' or '150p', where this last expression stands for 150 pence (same as 1.5£). In the case of currency symbols, when we trained the the algorithm we excluded them when we set this piece of code previously:\n",
    "\n",
    "    # Training set `SMS` cleaned series\n",
    "\n",
    "    # Eliminating punctuation.\n",
    "    cleaned = training_set.SMS.copy().str.replace('\\W', ' ', regex=True) \n",
    "\n",
    "Because we chose to replace an undiscriminated group of characters by setting `pattern='\\W'`, we prevented the algorithm from recognizing (at least some direct) money references, which are common in spam messages. Therefore, one way to improve the algorithm is to make it recognize currency or money expressions. \n",
    "\n",
    "\n",
    "For the sake of comprehension, we can find below all the suppressed characters in `training_set.SMS` which correspond to the regex character class 'not word' ('\\W'): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t',\n",
       " '\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '|',\n",
       " '~',\n",
       " '\\x91',\n",
       " '\\x92',\n",
       " '\\x93',\n",
       " '\\x94',\n",
       " '\\x96',\n",
       " '¡',\n",
       " '£',\n",
       " '»',\n",
       " '–',\n",
       " '—',\n",
       " '‘',\n",
       " '’',\n",
       " '“',\n",
       " '…',\n",
       " '┾'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_messages_str = ''\n",
    "\n",
    "for index, value in enumerate(training_set.SMS):\n",
    "    all_messages_str = ' '.join([all_messages_str, value])\n",
    "\n",
    "set(re.findall('\\W', all_messages_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table immediately below gives a short resume of various attempts of improving the algorithm's accuracy by tweaking what words/characters should be recognized in a message. The differences between versions 'a' and 'b' is that in the former, the message is converted into lower case, so that the algorithm recognizes the same word regardless of letter case. Version 'b' maintains the original case set. Because each variation on the algorithm has its own set of new procedures, which need to be thoroughly justified in order to make sense, I made a support Jupyter notebook - 'p14 - Spam Filter - Alternative Algorithm Versions (II, III and IV)', which explains the thought process behind the changes to the original algorithm.  \n",
    "\n",
    "| Version | Case sensitive | Accuracy (%) | Description                                                 |\n",
    "|---------|-----------|--------------|-------------------------------------------------------------|\n",
    "| 1a      | no        | 98.74        | Original version.                                         |\n",
    "| 1b      | yes       | 98.47        | ---                                                         |\n",
    "| 2a      | no        | 98.83        | Recognizes currency symbols: '£', '€' and '$'.                |\n",
    "| 2b      | yes       | 98.56        | ---                                                         |\n",
    "| 3a      | no        | 98.83        | Same as V2 but recognizes references to GBP pences. |\n",
    "| 3b      | yes        | 98.74        | ---                                                         |\n",
    "| 4a      | no        | 98.65       | Separate all numbers from letters and from other characters/symbols.|\n",
    "| 4b      | yes       |   98.47       | ---                                                         |\n",
    "\n",
    "\n",
    "In more detail, version 2 allows the algorithm to recognize the aforementioned currency symbols as a word (delimited with whitespaces), maintaining everything else the same as the original version. Version 3 adds to the version 2 a trench of code that allows the algorithm to also recognize references to British pound pences, as mentioned above, e.g. a message that includes this expression - '150p/text', will have it converted to '150p text', so that the reference to 150 pences can be recognized. Version 4 allows every sequence of either letters, digits or symbols to be isolated by a whitespace, and thus recognized as a single expression, e.g.: '150p/text' would become '150 p / text'. The idea for this version is that spam messages may have unusual or an excessive inclusion of hyperbolic symbols/characters such as many exclamation points. \n",
    "\n",
    "Analyzing the table above we can observe that the task of improving on the original accuracy test will be very difficult, given that it is already at 1.26\\% of being 100\\% accurate. The main point to be taken here is that tweaking the original algorithm did not improve or worsen significantly the algorithm's accuracy. Version's 2a and 3a were capable of accurately classify one more message correctly (each message is 0.09\\% from the total, which is the difference seen from version 1a to versions 2b and 3b). One detail that stands out is that making the the algorithm case sensitive slightly decreases its accuracy in all scenarios.   \n",
    "\n",
    "\n",
    "### Final Thoughts\n",
    "\n",
    "\n",
    "Since these variations of the algorithm were not up to the difficult task of reaching 100\\% accuracy, other implementations can be tried in future versions. These could be based on the attribution of a certain weight to the probability of spam, P(Spam|w1, w2,..., wn), given the number of capitalized words in a message: spam messages tend to be more hyperbolic, using more capital words; or by exploring the relation between spam messages and the number of characters per message (in relation to non-spam messages), in order to try to predict whether a really long message, with many characters, has the same probability of being spam or non-spam, when there is a suspicion that spam messages may be shorter and more to the point, than other types of messages. \n",
    "\n",
    "\n",
    "\n",
    "As a last remark, we can at least recognize that there was room to improve from the original algorithm's version, and if the algorithm was tested in other testing sets, the idea of recognizing symbols and expressions related to currency when classifying a message as spam or not is relevant. \n",
    "\n",
    "\\[End of Project\\]\n",
    "\n",
    "\\***"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "179px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "600.85px",
    "left": "1545px",
    "right": "20px",
    "top": "120px",
    "width": "355px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
