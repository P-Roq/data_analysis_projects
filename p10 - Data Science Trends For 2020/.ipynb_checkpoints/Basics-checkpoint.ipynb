{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Guided Project 8 - Popular Data Science Questions\n",
    "---\n",
    "From the tutorial:\n",
    "\n",
    "\n",
    "\"In this scenario, you're working for a company that creates data science content, be it books, online articles, videos or interactive text-based platforms like Dataquest.\n",
    "\n",
    "You're tasked with figuring out what is best content to write about. Because you took this course, you know that given the lack of instructions there's some leeway in what \"best\" means here.\n",
    "\n",
    "Since you're passionate about helping people learn, you decide to scour the internet in search for the answer to the question \"What is it that people want to learn about in data science?\" (as opposed to determining the most profitable content, for instance).\n",
    "\n",
    "Thinking back to your experience when you first started learning programming, it occurs to you that if you wanted to figure out what programming content to write, you could consult Stack Overflow (a question and answer website about programming) and see what kind of content is more popular.\n",
    "\n",
    "If you open the link in the image shared above, you'll find a complete list of Stack Exchange websites sorted by percentage of questions that received answers. At the time of this writing, [Data Science Stack Exchange (DSSE)](https://datascience.stackexchange.com/) is on the bottom 10 sites with respect to this metric.\n",
    "\n",
    "The fact that DSSE is a data science dedicated site (contrarily to the others), coupled with it having a lot of unanswered questions, makes it an ideal candidate for this investigation. DSSE will be the focus of this guided project.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "---\n",
    "- [Task 1](#Task_1)\n",
    "- [Task 2](#Task_2)\n",
    "- [Task 3](#Task_3)\n",
    "- [Task 4](#Task_4)\n",
    "- [Task 5](#Task_5)\n",
    "- [Task 6](#Task_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task_1\n",
    "---\n",
    "1. If you're not familiar with any Stack Exchange website, take the time to explore one of them. Try to answer a few of these questions in a markdown cell:\n",
    "\n",
    "    - 1.1. What kind of questions are welcome on this site?\n",
    "    \n",
    "    - 1.2. What, other than questions, does the site's home subdivide into?\n",
    "      - Does any of them look useful towards our goal?\n",
    "      \n",
    "    - 1.3. What information is available in each post?<P>\n",
    "    \n",
    "2. Explore some of the questions that were asked. **\\[omitted task\\]**<p>\n",
    "\n",
    "3. Try asking a couple of questions on any of Stack Exchange sites to get a better feel for how the sites operate. **\\[omitted task\\]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers - task #1\n",
    "\n",
    "1.1. As the [DSSE's tour page describes](https://datascience.stackexchange.com/tour), the type of questions that are welcome on the platform are 'pratical, detailed questions', related to data science. The same logic can be applied to any of the Stack Exchange websites, where this type of engagement is done under a wide but identifible subject such as the aforementioned case of data science, or others, like operating sistems (e.g. [Ask Ubuntu](https://askubuntu.com/https://askubuntu.com/)), languages (e.g. [English Language & Usage](https://english.stackexchange.com/)), etc.\n",
    "\n",
    "1.2. DSSE's home site is very directed to it's main purpose; the central and main section is composed by the essential tools that should allow the user to find questions useful to his/her purposes. At the top is the search bar, followed below by the 'Ask Question' link, main tags and useful filters tabs ('Active', 'Bountied', 'Hot', etc.). On the left is the organizational panel for the DSSE's site, which redirects to job search, and [private groups paid services](https://stackoverflow.com/teams). The right section is the list of the 'hottest' questions taken from all the Stack Exchange branches.\n",
    "\n",
    "From our frame of work, which is to look for 'what people want to lear about data science', what seems to be important is the clues provided by the meta-data gathered in form of tags. These key words allow to identify what are the most common concepts that arise from the pool of questions wich have many subject matters. Similarly, the 'hot' tab for example, is useful to know which subjects and concepts are being currently discussed in high volume. This offers the possibility to track in time the flow of interest shown in a given key concept or subject.\n",
    "\n",
    "1.3. Each post has the following main information:\n",
    "\n",
    "\n",
    " - From the poster side:\n",
    "     - Question title.\n",
    "     - Question content.\n",
    "     - Post info: 'Asked' (when was posted), 'Active'(last interaction), 'Viewed' (number of views).\n",
    "     - User info: name, score, reputation, badges.\n",
    "     - associated tags.\n",
    "     - question rating (by other users).\n",
    "     \n",
    "     \n",
    " - From the answer side:\n",
    "      - Answers from users, sorted by rating. For each answer:\n",
    "          - answer content\n",
    "          - user info (similar to 'user info' in the poster side)\n",
    "          - answer rating (from other users)\n",
    "          \n",
    "  - Comments:\n",
    "      - content.\n",
    "      - commenter user name.\n",
    "      \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task_2\n",
    "---\n",
    "### Preamble\n",
    "'After a spending some time investigating the website, you decide that the tags will be very useful in **categorizing content**, saving you the trouble of you having to do it yourself.\n",
    "\n",
    "Now comes the challenge of accessing the data en masse. One potential solution would be to scrape the site. However, because we still haven't learned how to web scrape, and because we have an easier alternative (mostly the second reason), we're going to do something else.\n",
    "\n",
    "Stack Exchange provides a public data base for each of its websites. [Here's](https://data.stackexchange.com/datascience/query/new) a link to query and explore Data Science Stack Exchange's database. \n",
    "\n",
    "\\(...\\)\n",
    "\n",
    "Note that SEDE uses a different dialect (Transact-SQL â€” Microsoft's SQL) than SQLite , which you learned earlier. Most things are the same, but some are different. \\(...\\) If you run into any issues due to these differences, try to research on your own how to solve them. [Here's](https://www.mssqltips.com/sqlservertip/4777/comparing-some-differences-of-sql-server-to-sqlite/) a helpful resource.'\n",
    "\n",
    "\n",
    "#### Instructions\n",
    "---\n",
    "1. Explore Data Science Stack Exchange's data model.  \n",
    "     - Investigate a few of the tables, especially those whose names sound more promising;\n",
    "     - Write a few queries to get a feel for the data; <p><p>   \n",
    "       \n",
    "2. In a markdown cell, write about what tables look more promising towards finding the most popular content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the tables available in DSSE's public data base (sql code):\n",
    "\n",
    "    SELECT \n",
    "            *\n",
    "    FROM INFORMATION_SCHEMA.TABLES\n",
    "    ORDER BY 1;\n",
    "    \n",
    "Output:\n",
    "\n",
    "|TABLE_NAME                |\n",
    "|--------------------------|\n",
    "|Badges                    |\n",
    "|CloseAsOffTopicReasonTypes|\n",
    "|CloseReasonTypes          |\n",
    "|Comments                  |\n",
    "|FlagTypes                 |\n",
    "|PendingFlags              |\n",
    "|PostFeedback              |\n",
    "|PostHistory               |\n",
    "|PostHistoryTypes          |\n",
    "|PostLinks                 |\n",
    "|PostNotices               |\n",
    "|PostNoticeTypes           |\n",
    "|Posts                     |\n",
    "|PostsWithDeleted          |\n",
    "|PostTags                  |\n",
    "|PostTypes                 |\n",
    "|ReviewRejectionReasons    |\n",
    "|ReviewTaskResults         |\n",
    "|ReviewTaskResultTypes     |\n",
    "|ReviewTasks               |\n",
    "|ReviewTaskStates          |\n",
    "|ReviewTaskTypes           |\n",
    "|SuggestedEdits            |\n",
    "|SuggestedEditVotes        |\n",
    "|Tags                      |\n",
    "|TagSynonyms               |\n",
    "|Users                     |\n",
    "|Votes                     |\n",
    "|VoteTypes                 |\n",
    "\n",
    "**Comment:** Looking at the tables availabe, starting to look for the desired information by exploring 'Posts' and 'Tags' seems reasonable.\n",
    "\n",
    "Taking a look at the basic info on the **'Posts'** table:\n",
    "\n",
    "        SELECT \n",
    "              COLUMN_NAME,\n",
    "              DATA_TYPE\n",
    "          FROM INFORMATION_SCHEMA.COLUMNS\n",
    "          WHERE TABLE_NAME = 'Posts';\n",
    "          \n",
    "Output:\n",
    "\n",
    "|COLUMN_NAME               |DATA_TYPE     |\n",
    "|--------------------------|--------------|\n",
    "|Id                        |int           |\n",
    "|PostTypeId                |tinyint       |\n",
    "|AcceptedAnswerId          |int           |\n",
    "|ParentId                  |int           |\n",
    "|CreationDate              |datetime      |\n",
    "|DeletionDate              |datetime      |\n",
    "|Score                     |int           |\n",
    "|ViewCount                 |int           |\n",
    "|Body                      |nvarchar      |\n",
    "|OwnerUserId               |int           |\n",
    "|OwnerDisplayName          |nvarchar      |\n",
    "|LastEditorUserId          |int           |\n",
    "|LastEditorDisplayName     |nvarchar      |\n",
    "|LastEditDate              |datetime      |\n",
    "|LastActivityDate          |datetime      |\n",
    "|Title                     |nvarchar      |\n",
    "|Tags                      |nvarchar      |\n",
    "|AnswerCount               |int           |\n",
    "|CommentCount              |int           |\n",
    "|FavoriteCount             |int           |\n",
    "|ClosedDate                |datetime      |\n",
    "|CommunityOwnedDate        |datetime      |\n",
    "|ContentLicense            |varchar       |\n",
    "\n",
    "**Comment:** the 'Posts' column has many columns but in order to understand what is the content users are after, one can look into the columns that register levels of engagement; belelow, using an exploratoty query into 'Posts', is an example of such columns:\n",
    "\n",
    "    SELECT \n",
    "        Top 5\n",
    "            Id,\n",
    "            ViewCount,\n",
    "            Score,\n",
    "            Tags,\n",
    "            AnswerCount,\n",
    "            CommentCount,\n",
    "            FavoriteCount\n",
    "        FROM Posts\n",
    "        ORDER BY ViewCount DESC;\n",
    "\n",
    "Output:\n",
    "\n",
    "|Id   |Title                                                                                                      |ViewCount|Score|Tags                                                 |AnswerCount|CommentCount|FavoriteCount|\n",
    "|-----|-----------------------------------------------------------------------------------------------------------|---------|-----|-----------------------------------------------------|-----------|------------|-------------|\n",
    "|11928|ValueError: Input contains NaN, infinity or a value too large for dtype('float32')                         |297432   |81   |python, random-forest, pandas                      |10         |2           |18           |\n",
    "|893  |How to get correlation between two categorical variable and a categorical variable and continuous variable?|290850   |103  |r, statistics, correlation                         |1          |5           |113          |\n",
    "|12321|What's the difference between fit and fit_transform in scikit-learn models?                                |282621   |210  |python, scikit-learn                               |10         |4           |154          |\n",
    "|13490|How to set class weights for imbalanced classes in Keras?                                                  |281734   |217  | deep-learning, classification, keras, weighted-data |9          |0           |85           |\n",
    "|33053|How do I compare columns in different data frames?                                                         |259993   |39   |pandas, dataframe                                  |6          |4           |15           |\n",
    "\n",
    "\n",
    "**Comment:** What is most sought after data science content can be extracted by defining different criteria. When looking at the sample from the 'Posts' table (shown above), one can be order the most popular content by view counts, or other columns such as number of answers or number of comments. \n",
    "\n",
    "\n",
    "We can also explore the table tags **'Tags'** to have a notion of what is available:\n",
    "\n",
    "        SELECT \n",
    "              COLUMN_NAME,\n",
    "              DATA_TYPE\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = 'Tags';\n",
    "            \n",
    "Output:\n",
    "\n",
    "|COLUMN_NAME    |DATA_TYPE|\n",
    "|---------------|---------|\n",
    "|Id             |int      |\n",
    "|TagName        |nvarchar |\n",
    "|Count          |int      |\n",
    "|ExcerptPostId  |int      |\n",
    "|WikiPostId     |int      |\n",
    "|IsModeratorOnly|bit      |\n",
    "|IsRequired     |bit      |\n",
    "\n",
    "\n",
    "\n",
    "Sampling 'Tags' by frequency ('Count'); hiighest 20 values:\n",
    "\n",
    "        SELECT \n",
    "          TOP 20\n",
    "              TagName,\n",
    "              Count\n",
    "          FROM Tags\n",
    "          ORDER BY COUNT DESC;\n",
    "          \n",
    "Output:\n",
    "\n",
    "|TagName            |Count|\n",
    "|-------------------|-----|\n",
    "|machine-learning   |9083 |\n",
    "|python             |5316 |\n",
    "|deep-learning      |3842 |\n",
    "|neural-network     |3731 |\n",
    "|classification     |2623 |\n",
    "|keras              |2354 |\n",
    "|nlp                |1877 |\n",
    "|scikit-learn       |1831 |\n",
    "|tensorflow         |1801 |\n",
    "|time-series        |1384 |\n",
    "|r                  |1295 |\n",
    "|regression         |1236 |\n",
    "|dataset            |1170 |\n",
    "|cnn                |1153 |\n",
    "|clustering         |1137 |\n",
    "|data-mining        |1054 |\n",
    "|pandas             |1040 |\n",
    "|predictive-modeling|1001 |\n",
    "|lstm               |942  |\n",
    "|statistics         |884  |\n",
    "\n",
    "\n",
    "**Comment:** The table immedialtely above displays the twenty most frequent tags associated to posts. From what we can see, these tags are mostly related to languages (e.g. python, r), libraries (e.g. pandas, scikit-learn), data analysis concepts (e.g. machine-learning, deep-learning) and statistical concepts (e.g. regression, time-series, clustering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task_3\n",
    "---\n",
    "### Preamble\n",
    "---\n",
    "The posts table has a lot of columns. We'll be focusing our attention on those that seem relevant towards our goal:\n",
    "\n",
    "- `Id`: An identification number for the post.\n",
    "\n",
    "- `PostTypeId`: An identification number for the type of post.\n",
    "    \n",
    "- `CreationDate`: The date and time of creation of the post.\n",
    "\n",
    "- `Score`: The post's score.\n",
    "    \n",
    "- `ViewCount`: How many times the post was viewed.\n",
    "\n",
    "-  `Tags`: What tags were used.\n",
    "    \n",
    "- `AnswerCount`: How many answers the question got (only applicable to question posts).\n",
    "\n",
    "- `FavoriteCount`: How many times the question was favored i.e. bookmarked by users (only applicable to question posts).\n",
    "\n",
    "Note that with the exception of the tags column, the last few columns contain information about how popular the post is â€” the kind of information we're after.\n",
    "\n",
    "There are eight different types of post. Before we try to figure out which of them are relevant to us, let's check how many of them there are:\n",
    "\n",
    "    SELECT \n",
    "            PostTypeId, \n",
    "            COUNT(*) as NrOfPosts\n",
    "        FROM posts\n",
    "        GROUP BY PostTypeId;\n",
    "        \n",
    "Output:\n",
    "\n",
    "|PostTypeId|NrOfPosts|\n",
    "|----------|---------|\n",
    "|1         |21446    |\n",
    "|2         |23673    |\n",
    "|4         |236      |\n",
    "|5         |236      |\n",
    "|6         |11       |\n",
    "|7         |1        |\n",
    "\n",
    "Due to their low volume, anything that isn't questions or answers is mostly inconsequential. Even if it happens to be the case that such kind of posts is immensely popular, they would just be outliers and not relevant to us. We'll then just focus on the questions.\n",
    "\n",
    "Since we're only interested in recent posts, we'll limit our analysis to the posts of 2019. (At the time of writing it is early 2020).\n",
    "\n",
    "The dataset we'll be using in this guided project is one resulting from a possible solution to the following exercise.\n",
    "\n",
    "#### Instructions\n",
    "---\n",
    "1. Run a query against the SEDE DSSE database that extracts the columns listed above for all the questions in 2019.\n",
    "\n",
    "Attempt of solution:\n",
    "\n",
    "    SELECT \n",
    "          Id,\n",
    "          PostTypeId,\n",
    "          CreationDate,\n",
    "          Score,\n",
    "          ViewCount,\n",
    "          Tags,\n",
    "          AnswerCount,\n",
    "          FavoriteCount\n",
    "      From Posts\n",
    "      WHERE (CreationDate >= '2019-01-01 00:00:00')\n",
    "      AND (CreationDate < '2020-01-01 00:00:00')\n",
    "      \n",
    "Two findings when looking in to the output:\n",
    "\n",
    "- Most cells in the `FavoriteCount` column are empty.\n",
    "- The values in the `Tags` column are stings with the following presentation, e.g. `row 0`: '<machine-learning><data-mining>'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task_4\n",
    "---\n",
    "1. Read in the file into a dataframe.   \n",
    "<br>   \n",
    "\n",
    "2. Explore the data. Try to answer a few of these questions in a markdown cell:\n",
    "    - How many missing values are there in each column?\n",
    "    - Can we fix the missing values somehow?\n",
    "    - Are the types of each column adequate?\n",
    "    - What can we do about the Tags column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading the file:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# using the full directory from my machine is not working:\n",
    "# df = pd.read_csv('/home/pi/documentos/dataquest/projects/p8 - Popular Data Science Questions (Data analysis in Business)/2019_questions.csv')\n",
    "\n",
    "# not using a full directory works in loading a csv file; probably one already made available by dataquest.\n",
    "df = pd.read_csv('2019_questions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First look by sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nulls = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nulls/8839*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the `Tags` column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# confirming that the `Tags` column is string type.\n",
    "\n",
    "type(df.iloc[0, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commments**\n",
    "\n",
    "- Only `FavoriteCounts` has missing values, which account for 84% of the total values.\n",
    "\n",
    "- Since `FavoriteCounts` is a personal choice of each user, of how important/useful a post is, if he/her decide to bookmark it, it's difficult to find viable proxy for this column; therefore, it can be dropped from the analysis since it does not provide consistent information.\n",
    "\n",
    "- Between objects - strings and datetime, and integers and floats, there are no surprises here; everything is 'workable'.\n",
    "\n",
    "- Since the values in `Tags` are strings, an easy cleaning can be applied, in order to extract each number of available tags per row. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task_5\n",
    "---\n",
    "### Preamble\n",
    "\n",
    "At the end of this screen, the types of the columns should be as follows.\n",
    "\n",
    "    Id                        int64\n",
    "    CreationDate     datetime64[ns]\n",
    "    Score                     int64\n",
    "    ViewCount                 int64\n",
    "    Tags                     object\n",
    "    AnswerCount               int64\n",
    "    FavoriteCount             int64\n",
    "\n",
    "#### Instructions\n",
    "---\n",
    "1. Fill in the missing values with 0.  \n",
    "   <br>\n",
    "2. Set the types of each column in accordance to what was illustrated above.   <br>\n",
    "    <br>\n",
    "3. Clean the Tags column and assign it back to itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling in zeros for `FavoriteCount`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['FavoriteCount'] = df['FavoriteCount'].mask(df['FavoriteCount'].isnull(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['FavoriteCount'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns that need to change types:\n",
    " - CreationDate: object to Datetime\n",
    " - FavoriteCount: float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.astype({'FavoriteCount':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.astype({'CreationDate':'datetime64[ns]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the column `Tags`:\n",
    "\n",
    "Note: to accomplish the tasks it is necessary to clean and reform the `Tags` colummn. For that purpose, this column will be split in a way that for each tag i (i in [0, n]) there is a column `Tag i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_tags = df['Tags'].str.split(pat=\"><\", expand=True)\n",
    "\n",
    "# Example of a `Tags` string: <machine-learning><data-mining>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_tags = split_tags.rename({0:'Tag_1', 1:'Tag_2', 2:'Tag_3', 3:'Tag_4', 4:'Tag_5'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_tags = split_tags.apply(lambda x: x.str.replace('(?:<|>)', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_tags = split_tags.fillna(value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# changing the original `Tags` column just to make it \n",
    "# tidy before closing the cleaning\n",
    "df['Tags'] = df['Tags'].str.replace(\"><\", ', ')\n",
    "df['Tags'] = df['Tags'].str.replace('(?:<|>)', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[split_tags.columns] = split_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After cleaning and joining to the main dataframe, we have: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** from what we can see, there are some overlapping tags such as in `Row 2` where we have forecast and forecasting in `Tag_3` and `Tag_4` respectively. Perhaps, a situation to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task_6\n",
    "---\n",
    "### Preamble\n",
    "---\n",
    "We now focus on determining the most popular tags. We'll do so by considering two different popularity proxies: **for each tag we'll count how many times the tag was used**, and **how many times a question with that tag was viewed**.\n",
    "\n",
    "We could take into account the score, or whether or not a question is part of someone's favorite questions. These are all reasonable options to investigate; but we'll limit the focus of our research to counts and views for now.\n",
    "\n",
    "#### Instructions\n",
    "---\n",
    "1. Count how many times each tag was used.   \n",
    "   <br>    \n",
    "2. Count how many times each tag was viewed.   \n",
    "   <br>\n",
    "3. Create visualizations for the top tags of each of the above results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5.1 Count how many times each tag was used. \n",
    "\n",
    "To count the tags used in the dataframe, I'll be doing a trick:\n",
    "  1. concating all tag columns in `df` (rows 7 to 11);\n",
    "  2. then, just use  the Series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concat_tags = pd.concat([df.iloc[:, 7],\n",
    "                        df.iloc[:, 8],\n",
    "                        df.iloc[:, 9],\n",
    "                        df.iloc[:, 10],\n",
    "                        df.iloc[:, 11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "used_tags = concat_tags.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 20 most used tags in the  `Posts` database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "used_tags.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Count how many times each tag was viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check = df.iloc[:, 7:12] == 'machine-learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check.any(1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series = pd.Series(index=used_tags.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_tags = list(used_tags.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "condition = df.iloc[0, 7:12] == 'machine-learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "condition.any(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_views = pd.Series(index=unique_tags)\n",
    "\n",
    "for row_1 in np.arange(0, len(unique_tags), 1):\n",
    "    tag = unique_tags[row_1]\n",
    "    tag_views[tag] = 0\n",
    "    for row_2 in np.arange(0, df.shape[0], 1):\n",
    "        condition = df.iloc[row_2, 7:12] == tag\n",
    "        if condition.any(0) == True:\n",
    "#             column 3 is `ViewCount`\n",
    "            tag_views[tag] += df.iloc[row_2, 3]   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_views.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "condition_x = df.iloc[:, 7:12] == 'machine-learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for tag in unique_tags:\n",
    "#     if df.iloc[:, 7:12]:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for el in np.arange(0, len(a), 1):\n",
    "    print(a[el])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
