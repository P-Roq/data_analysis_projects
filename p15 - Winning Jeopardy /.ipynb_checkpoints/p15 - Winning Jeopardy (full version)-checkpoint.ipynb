{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Project 13: Winning Jeopardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true,
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide 1\n",
    "---\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for many years, and is a major force in popular culture. If you need help at any point, you can consult our solution notebook [here](https://github.com/dataquestio/solutions/blob/master/Mission210Solution.ipynb).\n",
    "\n",
    "Imagine that you want to compete on Jeopardy, and you're looking for any way to win. In this project, you'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help you win.\n",
    "\n",
    "The dataset is named `jeopardy.csv`, and contains `20000` rows from the beginning of a full dataset of Jeopardy questions, which you can download [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file).\n",
    "\n",
    "As you can see, each row in the dataset represents a single question on a single episode of Jeopardy. Here are explanations of each column:\n",
    "\n",
    "- `Show Number` - the Jeopardy episode number.\n",
    "- `Air Date` - the date the episode aired.\n",
    "- `Round` - the round of Jeopardy.\n",
    "- `Category` - the category of the question.\n",
    "- `Value` - the number of dollars the correct answer is worth.\n",
    "- `Question` - the text of the question.\n",
    "- `Answer` - the text of the answer.\n",
    "\n",
    "\n",
    "#### Instructions\n",
    "---\n",
    "- Read the dataset into a Dataframe called `jeopardy` using Pandas.\n",
    "\n",
    "\n",
    "- Print out the first `5` rows of `jeopardy`.\n",
    "\n",
    "\n",
    "- Print out the columns of `jeopardy` using `jeopardy.columns`.\n",
    "\n",
    "\n",
    "- Some of the column names have spaces in front.\n",
    "    - Remove the spaces from each item in `jeopardy.columns`.\n",
    "    - Assign the result back to `jeopardy.columns` to fix the column names in `jeopardy`. \\[Note: Intead, I'm using `skipinitialspace=True` inside `pd.read_csv()` to eliminate those whitespaces.\\]\n",
    "    \n",
    "    \n",
    "- Pay close attention to the format of each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first look into the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy = pd.read_csv('jeopardy.csv', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Show Number  19999 non-null  int64 \n",
      " 1   Air Date     19999 non-null  object\n",
      " 2   Round        19999 non-null  object\n",
      " 3   Category     19999 non-null  object\n",
      " 4   Value        19999 non-null  object\n",
      " 5   Question     19999 non-null  object\n",
      " 6   Answer       19999 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 625.0+ KB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide 2\n",
    "---\n",
    "Before you can start doing analysis on the Jeopardy questions, you need to normalize all of the text columns (the `Question` and `Answer` columns). We covered normalization before, but the idea is to ensure that you put words in lowercase and remove punctuation so `Don't` and `don't` aren't considered to be different words when you compare them.\n",
    "\n",
    "\n",
    "#### Instructions\n",
    "---\n",
    "- Write a function to normalize questions and answers. The function should:\n",
    "    - Take in a string.\n",
    "    - Convert the string to lowercase.\n",
    "    - Remove all punctuation in the string.\n",
    "    - Return the string.\n",
    "    \n",
    "    \n",
    "- Normalize the `Question` column.\n",
    "    - Use the Pandas `Series.apply` method to apply the function to each item in the Question column.\n",
    "    - Assign the result to the `clean_question` column.\n",
    "    \n",
    "    \n",
    "- Normalize the Answer column.\n",
    "    - Use the Pandas `Series.apply` method to apply the function to each item in the `Answer` column.\n",
    "    - Assign the result to the `clean_answer` column.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing questions and answers.\n",
    "\n",
    "In order to make elements in the `Questions` column comparable to those in thee `Answers` column, I make a small normalization process for the two columns: \n",
    "\n",
    "- applying a function that lowercases strings and removes punctuation.\n",
    "- assigning changes to two new columns - `clean_question` and `clean_answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_string(string):\n",
    "    \"\"\"Takes in a string and lowercases it and removes punctuation.\"\"\"\n",
    "    \n",
    "    string_mod = str.lower(string)\n",
    "    string_mod = re.sub('\\W', ' ', string_mod)\n",
    "    \n",
    "    return string_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = jeopardy['Question'].apply(norm_string)\n",
    "\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(norm_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing two consecutive or more whitespaces into one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = \\\n",
    "    jeopardy['clean_question'].str.replace('\\s{2,}', ' ', regex=True)\n",
    "\n",
    "jeopardy['clean_answer'] = \\\n",
    "    jeopardy['clean_answer'].str.replace('\\s{2,}', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide 3\n",
    "---\n",
    "Now that you've normalized the text columns, there are also some other columns to normalize.\n",
    "\n",
    "The `Value` column should be numeric, to allow you to manipulate it easier. You'll need to remove the dollar sign from the beginning of each value and convert the column from text to numeric.\n",
    "\n",
    "The `Air Date` column should also be a datetime, not a string, to enable you to work it easier.\n",
    "\n",
    "\n",
    "\n",
    "#### Instructions\n",
    "---\n",
    "- Write a function to normalize dollar values. The function should:\n",
    "    - Take in a string.\n",
    "    - Remove any punctuation in the string.\n",
    "    - Convert the string to an integer.\n",
    "    - Assign `0` instead if the conversion has an error.\n",
    "    - Return the integer.\n",
    "    \n",
    "- Normalize the `Value` column.\n",
    "    - Use the Pandas `Series.apply` method to apply the function to each item in the Value column.\n",
    "    - Assign the result to the `clean_value` column.\n",
    "    \n",
    "    \n",
    "- Use the `pandas.to_datetime` function to convert the `Air Date` column to a datetime column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, a function to be applied on `Value` to turn the values into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_usd(string):\n",
    "    \"\"\"Converts a string/currency value into an integer.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        converted = re.sub('(\\$|,)', '', string)\n",
    "        converted = int(converted)\n",
    "    except:\n",
    "        converted = 0\n",
    "    \n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_value'] = jeopardy['Value'].apply(norm_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  200,   400,   600,   800,  2000,  1000,  1200,  1600,  3200,\n",
       "           0,  5000,   100,   300,   500,  1500,  4800,  1800,  1100,\n",
       "        2200,  3400,  3000,  4000,  6800,  1900,  3100,   700,  1400,\n",
       "        2800,  8000,  6000,  2400, 12000,  3800,  2500,  6200, 10000,\n",
       "        7000,  1492,  7400,  1300,  7200,  2600,  3300,  5400,  4500,\n",
       "        2100,   900,  3600,  2127,   367,  4400,  3500,  2900,  3900,\n",
       "        4100,  4600, 10800,  2300,  5600,  1111,  8200,  5800,   750,\n",
       "        7500,  1700,  9000,  6100,  1020,  4700,  2021,  5200,  3389],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['clean_value'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the column 'Air Date' can be converted to a datetime type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_air_date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide 4\n",
    "---\n",
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "\n",
    "- How often the answer can be used for a question.\n",
    "\n",
    "\n",
    "- How often questions are repeated.\n",
    "\n",
    "\n",
    "You can answer the second question by seeing how often complex words (> 6 characters) reoccur. You can answer the first question by seeing how many times words in the answer also occur in the question. We'll work on the first question and come back to the second.\n",
    "\n",
    "\n",
    "\n",
    "#### Instructions\n",
    "---\n",
    "- Write a function that takes in a row in `jeopardy`, as a Series. It should:\n",
    "    - Split the `clean_answer` column around spaces and assign to the variable `split_answer`.\n",
    "    - Split the `clean_question` column around spaces and assign to the variable `split_question`.\n",
    "    \n",
    "    \n",
    "- Create a variable called `match_count`, and set it to `0`.\n",
    "    - If `the` is in `split_answer`, remove (see its description below) it using the remove method on lists. '`The`' is commonly found in answers and questions, but doesn't have any meaningful use in finding the answer.\n",
    "    - If the length of `split_answer` is `0`, return `0`. This prevents a division by zero error later.\n",
    "    - Loop through each item in `split_answer`, and see if it occurs in `split_question`. If it does, add `1` to `match_count`.\n",
    "    - Divide `match_count` by the length of `split_answer`, and return the result.\n",
    "    \n",
    "    \n",
    "- Count how many times terms in `clean_answer` occur in `clean_question`.\n",
    "    - Use the Pandas `DataFrame.apply` method to apply the function to each row in `jeopardy`.\n",
    "    - Pass the `axis=1` argument to apply the function across each row.\n",
    "    - Assign the result to the `answer_in_question` column.\n",
    "    \n",
    "    \n",
    "- Find the mean of the `answer_in_question` column using the `mean` method on Series.\n",
    "\n",
    "\n",
    "- Write up a markdown cell with a short explanation of how finding this mean might influence your studying strategy for Jeopardy.\n",
    "\n",
    "\n",
    "From the Python's documentation:\n",
    "\n",
    "- list.remove(x)\n",
    "    - Remove the first item from the list whose value is equal to x. It raises a ValueError if there is no such item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(row):\n",
    "    \n",
    "    split_answer = row[\"clean_answer\"].split(' ')\n",
    "    split_question = row[\"clean_question\"].split(' ')\n",
    "    \n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "        \n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    \n",
    "    match_count = 0\n",
    "    \n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "            \n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(count_matches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'answer_in_question_mean = 6.93%'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_in_question_mean = round(jeopardy[\"answer_in_question\"].mean()*100, 2) \n",
    "\n",
    "f'{answer_in_question_mean = }%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "On average, only about 7% of the words in the question are also in the answer. This likely means that more often than not, question and associated answer can share common words such as 'a', 'an', 'for', etc, (see examples of a slice of cleaned answers below)\n",
    "hence frustrating the strategy of resorting to the words in the questions alone to find the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20                                              morocco\n",
       "21                                          paul bonwit\n",
       "22    hattie mcdaniel for her role in gone with the ...\n",
       "23                                                  era\n",
       "24                                   the congress party\n",
       "25                                     wilt chamberlain\n",
       "26                                                   k2\n",
       "27                                          ethan allen\n",
       "28                                                  ply\n",
       "29                                               horton\n",
       "30                                                nixon\n",
       "31                                             a kennel\n",
       "32                                                moses\n",
       "33                                            aerosmith\n",
       "34                                              oratory\n",
       "35                          coolidge or chester arthur \n",
       "36                                       business class\n",
       "37                                             muhammed\n",
       "38                                   the mystery train \n",
       "39                                     an old fashioned\n",
       "40                                               yertle\n",
       "Name: clean_answer, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.loc[20:40,'clean_answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide 5\n",
    "---\n",
    "Let's say you want to investigate how often new questions are repeats of older ones. You can't completely answer this, because you only have about `10%` of the full Jeopardy question dataset, but you can investigate it at least.\n",
    "\n",
    "\n",
    "To do this, you can:\n",
    "\n",
    "\n",
    "- Sort `jeopardy` in order of ascending air date.\n",
    "\n",
    "\n",
    "- Maintain a set called `terms_used` that will be empty initially.\n",
    "\n",
    "\n",
    "- Iterate through each row of `jeopardy`.\n",
    "\n",
    "\n",
    "- Split `clean_question` into words, remove any word shorter than `6` characters, and check if each word occurs in `terms_used`.\n",
    "    - If it does, increment a counter.\n",
    "    - Add each word to terms_used.\n",
    "\n",
    "\n",
    "This allows you to check if the terms in questions have been used previously or not. Only looking at words with six or more characters enables you to filter out words like `the` and `than`, which are commonly used, but don't tell you a lot about a question.\n",
    "\n",
    "\n",
    "\n",
    "#### Instructions\n",
    "---\n",
    "- Create an empty list called `question_overlap`.\n",
    "\n",
    "\n",
    "- Create an empty set called `terms_used`.\n",
    "\n",
    "\n",
    "- Sort jeopardy by ascending air date.\n",
    "- Use the `iterrows` Dataframe method to loop through each row of `jeopardy`.\n",
    "    - Split the `clean_question` column of the row on the space character (` `), and assign to `split_question`.\n",
    "    - Remove any words in `split_question` that are less than 6 characters long.\n",
    "    - Set `match_count` to `0`.\n",
    "    - Loop through each word in `split_question`.\n",
    "        - If the term occurs in `terms_used`, add `1` to `match_count`.\n",
    "    - Add each word in `split_question` to `terms_used` using the `add` method on sets.\n",
    "    - If the length of `split_question` is greater than `0`, divide `match_count` by the length of `split_question`.\n",
    "    - Append `match_count` to `question_overlap`.\n",
    "    \n",
    "    \n",
    "- Assign question_overlap to the question_overlap column of jeopardy.\n",
    "\n",
    "\n",
    "- Find the mean of the `question_overlap` column and print it.\n",
    "\n",
    "\n",
    "- Look at the value, and think about what this might mean for questions being recycled. Write up your thoughts in a markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answering the question - 'how often questions are repeated', by seeing how often complex words (> 6 characters) reoccur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary clean-up: ordering questions by show air date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy = jeopardy.sort_values(by='Air Date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process below, Stage 2 (marked as a comment) is divided into two loops - 'a' and 'b', so that we can register repeated words among questions/rows and thus avoid counting repeated words within the same question as re-occurrences. Mind as well that there is a time logic behind this process, hence the questions being sorted by air date: occurrences only happen when we compare one question with questions that appeared in past shows (or in the same air date). \n",
    "\n",
    "Sets can form random orders each time they are created, even if they have the same content. Because of that, it is better to perform the loop process once, in order to fill out `terms_used` with the desired terms, convert it into a list, and save it externally, so that we can preserve the order of the values. Since `question_overlap` is derived from `terms_used`, we save it as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    question_overlap = []\n",
    "\n",
    "    terms_used = set()\n",
    "\n",
    "    for index, val in enumerate(jeopardy['clean_question']):\n",
    "\n",
    "        ## Stage 1.\n",
    "        split_question = val.split(' ')\n",
    "\n",
    "        split_question = [word for word in split_question if len(word) >= 6]\n",
    "\n",
    "\n",
    "        ## Stage 2.\n",
    "        match_count = 0\n",
    "\n",
    "        # Loop a.\n",
    "        for word in split_question:\n",
    "            if word in terms_used:\n",
    "                match_count += 1\n",
    "\n",
    "        # Loop b.\n",
    "        for word in split_question:\n",
    "            terms_used.add(word)\n",
    "\n",
    "\n",
    "        ## Stage 3. \n",
    "        if len(split_question):\n",
    "            match_count /= len(split_question)\n",
    "\n",
    "        question_overlap.append(match_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note:** `set` objects are very ambiguous in retaining a specific order, the best way to avoid reading back the same set object with a different order, e.g. you save this: set(['a', 'b', 'c']) and when you read it back it can appear with a random order every time, like this: set(['a', 'c', 'b']) or set(['b', 'c', 'a']). The best practice is to convert the set object into a list and then save it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    import pickle\n",
    "\n",
    "\n",
    "    # Creating a binary pickle file for each object.\n",
    "    qo = open(\"question_overlap.pkl\",\"wb\") \n",
    "    tu = open(\"terms_used.pkl\",\"wb\") \n",
    "\n",
    "    # Write the python object to pickle file.\n",
    "    pickle.dump(question_overlap, qo)\n",
    "    pickle.dump(list(terms_used), tu) # converted into a list before saving\n",
    "\n",
    "    # close file\n",
    "    qo.close()\n",
    "    tu.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the objects back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_overlap = pd.read_pickle(\"question_overlap.pkl\") # original variable overwritten\n",
    "\n",
    "terms_used_list = pd.read_pickle(\"terms_used.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.5\n",
       "4    0.0\n",
       "Name: question_overlap, dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['question_overlap'] = pd.Series(question_overlap)\n",
    "\n",
    "jeopardy['question_overlap'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question_overlap_mean = 71.98%'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap_mean = jeopardy['question_overlap'].mean()\n",
    "\n",
    "question_overlap_mean = round(question_overlap_mean*100, 2)\n",
    "\n",
    "f'{question_overlap_mean = }%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "The value above means that, on average, aprox. 72% of the words used in a question were already used in a previous similar question.\n",
    "\n",
    "The validity of the previous method as a mean capable of identifying repeated questions is dubious. First, resorting to a bank of repeated words to determine which words in a given question are also repeated may not be very useful, since the same words may be used to formulate different questions. Also, computing the ratio of repeated words of a question in relation to the total number of words does not make great sense; by definition, categorizing a question as repeated entails that a previous question, which had the same context, also was answered similarly (in this case we seek identical answers). We are looking for a binary situation such as: 'is this question a repeated one or not?'; we should not seek to answer: 'this question is 75% repeated' because three out of four words were used randomly (i.e. in various possible contexts) in past questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide 6\n",
    "---\n",
    "Let's say you only want to study questions that pertain to high value questions instead of low value questions. This will help you earn more money when you're on Jeopardy.\n",
    "\n",
    "You can actually figure out which terms correspond to high-value questions using a chi-squared test. You'll first need to narrow down the questions into two categories:\n",
    "\n",
    "- Low value -- Any row where `Value` is less than `800`.\n",
    "- High value -- Any row where `Value` is greater than `800`.\n",
    "\n",
    "You'll then be able to loop through each of the terms from the last screen, `terms_used`, and:\n",
    "\n",
    "\n",
    "- Find the number of low value questions the word occurs in.\n",
    "\n",
    "\n",
    "- Find the number of high value questions the word occurs in.\n",
    "\n",
    "\n",
    "- Find the percentage of questions the word occurs in.\n",
    "\n",
    "\n",
    "- Based on the percentage of questions the word occurs in, find expected counts.\n",
    "\n",
    "\n",
    "- Compute the chi squared value based on the expected counts and the observed counts for high and low value questions.\n",
    "\n",
    "You can then find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. Doing this for all of the words would take a very long time, so we'll just do it for a small sample now.\n",
    "\n",
    "\n",
    "\n",
    "#### Instructions\n",
    "---\n",
    "1. Create a function that takes in a row from a Dataframe, and:\n",
    "    - If the `clean_value` column is greater than `800`, assign `1` to `value`.\n",
    "    - Otherwise, assign `0` to `value`.\n",
    "    - Return value.\n",
    "    \n",
    "    \n",
    "2. Determine which questions are high and low value.\n",
    "    - Use the Pandas DataFrame.apply method to apply the function to each row in `jeopardy`.\n",
    "    - Pass the `axis=1` argument to apply the function across each row.\n",
    "    - Assign the result to the `high_value` column.\n",
    "    \n",
    "    \n",
    "3. Create a function that takes in a word, and:\n",
    "    - Assigns `0` to `low_count`.\n",
    "    - Assigns `0` to `high_count`.\n",
    "    - Loops through each row in `jeopardy` using the `iterrows` method.\n",
    "    - Split the `clean_question` column on the space character (` `).\n",
    "    - If the word is in the split question:\n",
    "        - If the `high_value` column is `1`, add `1` to `high_count`.\n",
    "        - Else, add `1` to `low_count`.\n",
    "    - Returns `high_count` and `low_count`. You can return multiple values by separating them with a comma.\n",
    "    \n",
    "    \n",
    "4. Randomly pick ten elements of `terms_used` and append them to a list called `comparison_terms`.\n",
    "\n",
    "\n",
    "5. Create an empty list called `observed_expected`.\n",
    "\n",
    "\n",
    "6. Loop through each term in `comparison_terms`, and:\n",
    "    - Run the function on the term to get the high value and low value counts.\n",
    "    - Append the result of running the function (which will be a list) to `observed_expected`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplifying the process above in the following steps:\n",
    "\n",
    "1. creating a new column that defines each question/row as 'high value' or 'low_value'. \n",
    "2. picking randomly 10 terms from the `terms_used` pool.\n",
    "3. building the function that counts for each term chosen in 2. the number of high value and low value questions that contain that expression (a least once).\n",
    "4. instead of filling out a list of lists with the output generated in 3., a Series called 'observed' will be created to save that output (`observed_expected` is created later on). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. classify each question/row as high value or low value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_value</th>\n",
       "      <th>high_or_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>800</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1900</td>\n",
       "      <td>high_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>800</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1000</td>\n",
       "      <td>high_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1000</td>\n",
       "      <td>high_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>400</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1000</td>\n",
       "      <td>high_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>400</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>400</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>400</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>100</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clean_value high_or_low\n",
       "80          800   low_value\n",
       "81         1900  high_value\n",
       "82          800   low_value\n",
       "83         1000  high_value\n",
       "84         1000  high_value\n",
       "85          400   low_value\n",
       "86         1000  high_value\n",
       "87          400   low_value\n",
       "88          400   low_value\n",
       "89          400   low_value\n",
       "90          100   low_value"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['high_or_low'] = jeopardy['clean_value'].apply(lambda x: 'high_value' if x > 800 else 'low_value')\n",
    "\n",
    "# checking new column, random look.\n",
    "jeopardy.loc[80:90, ['clean_value', 'high_or_low']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. randomly pick 10 terms from `terms_used` and save them into a list - `comparison_term`. Only done once, output saved in the list below, to prevent overwriting.\n",
    "\n",
    "        import random\n",
    "\n",
    "        comparison_term = random.sample(terms_used_list, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "comparison_term = ['coronado',\n",
    "                  'residence',\n",
    "                  'subatomic',\n",
    "                  'halston',\n",
    "                  'nuremberg',\n",
    "                  'plumber',\n",
    "                  'osment',\n",
    "                  'tortured',\n",
    "                  'relatively',\n",
    "                  'herradura']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. build the function that counts how many high value and low value questions contain each one of the terms in `comparison_term`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_highs_and_lows(word):\n",
    "    \"\"\"Takes a word and returns how many times that word was used in high value questions\n",
    "    and low value questions.\n",
    "    \"\"\"\n",
    "    \n",
    "    high_counts = 0\n",
    "    low_counts = 0\n",
    "    \n",
    "    for i, val in enumerate(jeopardy['clean_question']):\n",
    "        \n",
    "        split = val.split(' ')\n",
    "        \n",
    "        if word in split:\n",
    "            if jeopardy.loc[i, 'high_or_low'] == 'high_value':\n",
    "                high_counts += 1\n",
    "            else:\n",
    "                low_counts += 1\n",
    "\n",
    "    return [high_counts, low_counts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. apply function and display results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 0]\n",
       "1    [4, 4]\n",
       "2    [1, 1]\n",
       "3    [0, 1]\n",
       "4    [1, 0]\n",
       "5    [1, 1]\n",
       "6    [1, 0]\n",
       "7    [0, 1]\n",
       "8    [0, 3]\n",
       "9    [0, 1]\n",
       "Name: observed, dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_list = [count_highs_and_lows(word) for word in comparison_term]\n",
    "\n",
    "observed = pd.Series(observed_list, name='observed')\n",
    "\n",
    "observed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide 7\n",
    "---\n",
    "Now that you've found the observed counts for a few terms, you can compute the expected counts and the chi-squared value.\n",
    "\n",
    "\n",
    "#### Instructions\n",
    "---\n",
    "1. Find the number of rows in `jeopardy` where `high_value` is `1`, and assign to `high_value_count`. \n",
    "\n",
    "\n",
    "2. Find the number of rows in `jeopardy` where `high_value` is `0`, and assign to `low_value_count`. \n",
    "\n",
    "\n",
    "3. Create an empty list called `chi_squared`.\n",
    "\n",
    "\n",
    "4. Loop through each list in `observed_expected`.\n",
    "    - Add up both items in the list (high and low counts) to get the total count, and assign to `total`.\n",
    "    - Divide `total` by the number of rows in` jeopardy` to get the proportion across the dataset. Assign to `total_prop`.\n",
    "    - Multiply `total_prop` by `high_value_count` to get the expected term count for high value rows.\n",
    "    - Multiply `total_prop` by `low_value_count` to get the expected term count for low value rows.\n",
    "    - Use the `scipy.stats.chisquare` function to compute the chi-squared value and p-value given the expected and observed counts.\n",
    "    - Append the results to `chi_squared`.\n",
    "    \n",
    "    \n",
    "5. Look over the chi-squared values and the associated p-values. Are there any statistically significant results? Write up your thoughts in a markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of high value questions and low value questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high_value_count = 5734\n",
      "low_value_count = 14265\n"
     ]
    }
   ],
   "source": [
    "high_value_count = jeopardy[jeopardy['high_or_low']=='high_value'].shape[0]\n",
    "\n",
    "low_value_count = jeopardy[jeopardy['high_or_low']!='high_value'].shape[0]\n",
    "\n",
    "# checking counts:\n",
    "print(f'{high_value_count = }', f'{low_value_count = }', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing expected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.28671433571678584, 0.7132856642832142]\n",
       "1      [2.2937146857342867, 5.706285314265713]\n",
       "2     [0.5734286714335717, 1.4265713285664283]\n",
       "3    [0.28671433571678584, 0.7132856642832142]\n",
       "4    [0.28671433571678584, 0.7132856642832142]\n",
       "5     [0.5734286714335717, 1.4265713285664283]\n",
       "6    [0.28671433571678584, 0.7132856642832142]\n",
       "7    [0.28671433571678584, 0.7132856642832142]\n",
       "8     [0.8601430071503575, 2.1398569928496425]\n",
       "9    [0.28671433571678584, 0.7132856642832142]\n",
       "Name: expected, dtype: object"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected = []\n",
    "\n",
    "for i, val in enumerate(observed):\n",
    "    \n",
    "    # High and Low value count.\n",
    "    high_count = val[0]\n",
    "    low_count = val[1]\n",
    "    \n",
    "    # Proportion of words vs total number of questions\n",
    "    total_prop = (high_count + low_count) / jeopardy.shape[0]\n",
    "    \n",
    "    expected_high = total_prop * high_value_count\n",
    "    expected_low = total_prop * low_value_count\n",
    "    \n",
    "#     expected.append([round(expected_high, 10), round(expected_low, 10)])\n",
    "    expected.append([expected_high, expected_low])\n",
    "    \n",
    "expected = pd.Series(expected, name='expected')\n",
    "\n",
    "expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting observed and expected values in a DataFrame: `observed_expected`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coronado</th>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.28671433571678584, 0.7132856642832142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residence</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>[2.2937146857342867, 5.706285314265713]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subatomic</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.5734286714335717, 1.4265713285664283]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>halston</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.28671433571678584, 0.7132856642832142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuremberg</th>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.28671433571678584, 0.7132856642832142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plumber</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.5734286714335717, 1.4265713285664283]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osment</th>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.28671433571678584, 0.7132856642832142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tortured</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.28671433571678584, 0.7132856642832142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relatively</th>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>[0.8601430071503575, 2.1398569928496425]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herradura</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.28671433571678584, 0.7132856642832142]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           observed                                   expected\n",
       "coronado     [1, 0]  [0.28671433571678584, 0.7132856642832142]\n",
       "residence    [4, 4]    [2.2937146857342867, 5.706285314265713]\n",
       "subatomic    [1, 1]   [0.5734286714335717, 1.4265713285664283]\n",
       "halston      [0, 1]  [0.28671433571678584, 0.7132856642832142]\n",
       "nuremberg    [1, 0]  [0.28671433571678584, 0.7132856642832142]\n",
       "plumber      [1, 1]   [0.5734286714335717, 1.4265713285664283]\n",
       "osment       [1, 0]  [0.28671433571678584, 0.7132856642832142]\n",
       "tortured     [0, 1]  [0.28671433571678584, 0.7132856642832142]\n",
       "relatively   [0, 3]   [0.8601430071503575, 2.1398569928496425]\n",
       "herradura    [0, 1]  [0.28671433571678584, 0.7132856642832142]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected = pd.concat([observed, expected], axis=1)\n",
    "\n",
    "observed_expected.index = comparison_term\n",
    "\n",
    "observed_expected "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually finding the chi-square value of the first term in `observed_expected` - 'coronado':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion_diff_sq(a, b):\n",
    "    \"\"\"Takes two numbers, a and b, and returns their proportional\n",
    "    difference. The dividend is squared.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return (a - b)**2 / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.487792117195675"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_value_chi = proportion_diff_sq(observed_expected.iloc[0, 0][0], observed_expected.iloc[0, 1][0])\n",
    "\n",
    "low_value_chi = proportion_diff_sq(observed_expected.iloc[0, 0][1], observed_expected.iloc[0, 1][1])\n",
    "\n",
    "composit_chi = high_value_chi + low_value_chi\n",
    "\n",
    "composit_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producing the chi-square tests and associated p-values for every term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chi-square value</th>\n",
       "      <th>p-value</th>\n",
       "      <th>over 5% threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coronado</th>\n",
       "      <td>2.487792</td>\n",
       "      <td>0.114733</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residence</th>\n",
       "      <td>1.779510</td>\n",
       "      <td>0.182210</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subatomic</th>\n",
       "      <td>0.444877</td>\n",
       "      <td>0.504778</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>halston</th>\n",
       "      <td>0.401963</td>\n",
       "      <td>0.526077</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuremberg</th>\n",
       "      <td>2.487792</td>\n",
       "      <td>0.114733</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plumber</th>\n",
       "      <td>0.444877</td>\n",
       "      <td>0.504778</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osment</th>\n",
       "      <td>2.487792</td>\n",
       "      <td>0.114733</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tortured</th>\n",
       "      <td>0.401963</td>\n",
       "      <td>0.526077</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relatively</th>\n",
       "      <td>1.205889</td>\n",
       "      <td>0.272148</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herradura</th>\n",
       "      <td>0.401963</td>\n",
       "      <td>0.526077</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            chi-square value   p-value over 5% threshold\n",
       "term                                                    \n",
       "coronado            2.487792  0.114733               yes\n",
       "residence           1.779510  0.182210               yes\n",
       "subatomic           0.444877  0.504778               yes\n",
       "halston             0.401963  0.526077               yes\n",
       "nuremberg           2.487792  0.114733               yes\n",
       "plumber             0.444877  0.504778               yes\n",
       "osment              2.487792  0.114733               yes\n",
       "tortured            0.401963  0.526077               yes\n",
       "relatively          1.205889  0.272148               yes\n",
       "herradura           0.401963  0.526077               yes"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare \n",
    "\n",
    "chi_squared = []\n",
    "\n",
    "for index, series in observed_expected.iterrows():\n",
    "    \n",
    "    obs = series[0]\n",
    "    exp = series[1]\n",
    "\n",
    "    chisquare_value, pvalue  = chisquare(obs, exp)\n",
    "    \n",
    "    chi_squared.append([chisquare_value, pvalue])\n",
    "    \n",
    "chi_squared_df = pd.DataFrame(chi_squared,\n",
    "                              columns=['chi-square value', 'p-value'],\n",
    "                              index=comparison_term).rename_axis('term')\n",
    "\n",
    "chi_squared_df['over 5% threshold'] = chi_squared_df['p-value'].apply(lambda x: 'yes' if x > 0.05 else 'no')\n",
    "\n",
    "chi_squared_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment\n",
    "\n",
    "Following the tutorial's instructions leads us to a major problem that invalidates the tests' results shown above. The problem stems from the fact that, when sampling for complex words (terms), we are not taking into account that questions with such terms have extremely low observed counts. From the [scipy documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html):\n",
    "\n",
    "'This test is invalid when the observed or expected frequencies in each category are too small. A typical rule is that all of the observed and expected frequencies should be at least 5. According to [3], the total number of samples is recommended to be greater than 13, otherwise exact tests (such as Barnard’s Exact test) should be used because they do not overreject.'\n",
    "\n",
    "Also, simply looking at the chi-square value magnitude is not enough to determine whether a term is more likely to be occurring in high value questions since the squared proportion difference of low value questions may be the component that inflates the chi-square value. Recall the chi-square value for the present scenario:\n",
    "\n",
    "\\begin{equation}\n",
    "\\chi^{2} = \\frac{(\\text{high value obs} - \\text{high value exp})^2}{\\text{high value exp}} + \n",
    "       \\frac{(\\text{low value obs} - \\text{low value exp})^2}{\\text{low value exp}}  \n",
    "\\end{equation}\n",
    "\n",
    "Despite of the tests being invalid, for practicing purposes, reading them as is, would indicate that 'none of the terms had a significant difference in usage between high value and low value rows' (from the solution notebook, which finds similar results).\n",
    "\n",
    "Furthermore, from single term alone, is difficult to assess the overall context in which they are being used, e.g. if we can infer that History of World War II is a recurrent topic because of the term 'nuremberg' as in 'Nuremberg Trials', not much can be said about what subjects, 'residence' or 'relatively', are alluding to. \n",
    "\n",
    "Regarding the chi-square test, two immediate improvements can be made:\n",
    "\n",
    " - a) consider only terms that can be found more often in high value questions than in low value questions. To this end, we can make a chain of procedures:\n",
    "    1. calculate for every term the difference between (observed) high value and low value questions counts.\n",
    "    2. sort terms/rows, in descending order, based on the magnitude of the differences in counts calculated in Step 1.\n",
    "    3. drop all rows when the difference between high and low count is not positive (we only are interested in terms that appear more often in high value than low value questions).\n",
    "    4. slice the DataFrame, so that it only contains the top 100 terms which have the greatest differences.\n",
    "    5. compute the expected values for each term/row.\n",
    "\n",
    "\n",
    " - b) from the final output produced in a), filter that DataFrame, selecting only the terms that have observed and expected values over 5. \n",
    "\n",
    "---\n",
    "\n",
    "#### Starting with a):\n",
    " - Since we are computing the observed values for 21223 terms, we apply the `count_highs_and_lows` in `terms_used_series`  once and save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_used_series = pd.Series(terms_used_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    observed_2 = terms_used_series.apply(count_highs_and_lows) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resorting to the pickle library again to save the `observed_2` output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    obsr_2 = open(\"observed_2.pkl\",\"wb\") \n",
    "\n",
    "    pickle.dump(observed_2, obsr_2)\n",
    "\n",
    "    obsr_2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_2_series = pd.read_pickle('observed_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_2_df = pd.DataFrame({'observed': observed_2_series}).set_index(terms_used_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>croatia</th>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campuses</th>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accumulate</th>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voyages</th>\n",
       "      <td>[0, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emeritus</th>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           observed\n",
       "croatia      [2, 3]\n",
       "campuses     [1, 1]\n",
       "accumulate   [1, 0]\n",
       "voyages      [0, 3]\n",
       "emeritus     [1, 0]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we compute the differences between high value and low value counts for each term/row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_2_df['difference'] = observed_2_df.observed.apply(lambda x: x[0] - x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>[37, 17]</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>painter</th>\n",
       "      <td>[17, 10]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>[16, 10]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>largely</th>\n",
       "      <td>[5, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creates</th>\n",
       "      <td>[6, 1]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hormone</th>\n",
       "      <td>[8, 3]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spirit</th>\n",
       "      <td>[13, 8]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orator</th>\n",
       "      <td>[8, 3]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>[13, 8]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyphenated</th>\n",
       "      <td>[8, 3]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            observed  difference\n",
       "monitor     [37, 17]          20\n",
       "painter     [17, 10]           7\n",
       "example     [16, 10]           6\n",
       "largely       [5, 0]           5\n",
       "creates       [6, 1]           5\n",
       "hormone       [8, 3]           5\n",
       "spirit       [13, 8]           5\n",
       "orator        [8, 3]           5\n",
       "andrew       [13, 8]           5\n",
       "hyphenated    [8, 3]           5"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_2_df_sorted = observed_2_df.sort_values('difference', ascending=False)\n",
    "\n",
    "observed_2_df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only terms with positive differences - high counts higher than low counts, and also keep only the top 100 terms that have the greatest difference between counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>[37, 17]</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>painter</th>\n",
       "      <td>[17, 10]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>[16, 10]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>largely</th>\n",
       "      <td>[5, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creates</th>\n",
       "      <td>[6, 1]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         observed  difference\n",
       "monitor  [37, 17]          20\n",
       "painter  [17, 10]           7\n",
       "example  [16, 10]           6\n",
       "largely    [5, 0]           5\n",
       "creates    [6, 1]           5"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_over_0 = observed_2_df_sorted[observed_2_df_sorted.difference > 0]\n",
    "\n",
    "difference_top_100 = difference_over_0.head(100).copy()\n",
    "\n",
    "difference_top_100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the expected high and low counts applying the function `find_expected`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_expected(observed_list):\n",
    "\n",
    "    # High and Low value count.\n",
    "    high_count = observed_list[0]\n",
    "    low_count = observed_list[1]\n",
    "\n",
    "    # Proportion of words vs total number of questions\n",
    "    total_prop = (high_count + low_count) / jeopardy.shape[0]\n",
    "\n",
    "    expected_high = total_prop * high_value_count\n",
    "    expected_low = total_prop * low_value_count\n",
    "\n",
    "    return [expected_high, expected_low]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed</th>\n",
       "      <th>difference</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>[37, 17]</td>\n",
       "      <td>20</td>\n",
       "      <td>[15.482574128706435, 38.51742587129356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>painter</th>\n",
       "      <td>[17, 10]</td>\n",
       "      <td>7</td>\n",
       "      <td>[7.741287064353218, 19.25871293564678]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>[16, 10]</td>\n",
       "      <td>6</td>\n",
       "      <td>[7.454572728636432, 18.545427271363568]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>largely</th>\n",
       "      <td>[5, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.4335716785839292, 3.566428321416071]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creates</th>\n",
       "      <td>[6, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>[2.007000350017501, 4.992999649982499]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         observed  difference                                 expected\n",
       "monitor  [37, 17]          20  [15.482574128706435, 38.51742587129356]\n",
       "painter  [17, 10]           7   [7.741287064353218, 19.25871293564678]\n",
       "example  [16, 10]           6  [7.454572728636432, 18.545427271363568]\n",
       "largely    [5, 0]           5  [1.4335716785839292, 3.566428321416071]\n",
       "creates    [6, 1]           5   [2.007000350017501, 4.992999649982499]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_top_100['expected'] = difference_top_100['observed'].apply(find_expected)\n",
    "\n",
    "difference_top_100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task b)\n",
    "\n",
    "Creating a procedure to find out questions/rows that have both observed and expected values, high and low, equal or over 5, so that we can apply a valid chi-square test to each row.\n",
    "\n",
    "In the `df.iterrows()` process below, we go over the observed and expected values in each list (high and low value), and save the index value/term in `index_values_over_4`, whenever all those values are equal to 5 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_values_over_4 = []\n",
    "\n",
    "for index, series in difference_top_100.iterrows():\n",
    "    \n",
    "    # example of `observed_expected`: [37, 17, 15.482574128706435, 38.51742587129356]\n",
    "    observed_expected = []\n",
    "    \n",
    "    observed_expected += series[0]\n",
    "    observed_expected += series[2]\n",
    "    \n",
    "    check_over_4 = [True for el in observed_expected if el >= 5]\n",
    "    \n",
    "    # check_over_4 can only have 4 elements, [True, True, True, True], \n",
    "    # if all values in observed_expected are over 4. \n",
    "    if len(check_over_4) == 4:\n",
    "        index_values_over_4.append(series.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producing the final DataFrame for testing - `observed_expected_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12 entries, monitor to plants\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   observed    12 non-null     object\n",
      " 1   difference  12 non-null     int64 \n",
      " 2   expected    12 non-null     object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 240.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "observed_expected_2 = difference_top_100.loc[index_values_over_4, :]\n",
    "\n",
    "observed_expected_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed</th>\n",
       "      <th>difference</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>[37, 17]</td>\n",
       "      <td>20</td>\n",
       "      <td>[15.482574128706435, 38.51742587129356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>painter</th>\n",
       "      <td>[17, 10]</td>\n",
       "      <td>7</td>\n",
       "      <td>[7.741287064353218, 19.25871293564678]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>[16, 10]</td>\n",
       "      <td>6</td>\n",
       "      <td>[7.454572728636432, 18.545427271363568]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spirit</th>\n",
       "      <td>[13, 8]</td>\n",
       "      <td>5</td>\n",
       "      <td>[6.021001050052503, 14.978998949947497]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>[13, 8]</td>\n",
       "      <td>5</td>\n",
       "      <td>[6.021001050052503, 14.978998949947497]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liquid</th>\n",
       "      <td>[17, 12]</td>\n",
       "      <td>5</td>\n",
       "      <td>[8.31471573578679, 20.68528426421321]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulitzer</th>\n",
       "      <td>[15, 11]</td>\n",
       "      <td>4</td>\n",
       "      <td>[7.454572728636432, 18.545427271363568]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>african</th>\n",
       "      <td>[43, 39]</td>\n",
       "      <td>4</td>\n",
       "      <td>[23.51057552877644, 58.48942447122356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>[16, 12]</td>\n",
       "      <td>4</td>\n",
       "      <td>[8.028001400070004, 19.971998599929996]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>[13, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.594429721486074, 16.405570278513927]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marine</th>\n",
       "      <td>[12, 9]</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.021001050052503, 14.978998949947497]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plants</th>\n",
       "      <td>[12, 9]</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.021001050052503, 14.978998949947497]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          observed  difference                                 expected\n",
       "monitor   [37, 17]          20  [15.482574128706435, 38.51742587129356]\n",
       "painter   [17, 10]           7   [7.741287064353218, 19.25871293564678]\n",
       "example   [16, 10]           6  [7.454572728636432, 18.545427271363568]\n",
       "spirit     [13, 8]           5  [6.021001050052503, 14.978998949947497]\n",
       "andrew     [13, 8]           5  [6.021001050052503, 14.978998949947497]\n",
       "liquid    [17, 12]           5    [8.31471573578679, 20.68528426421321]\n",
       "pulitzer  [15, 11]           4  [7.454572728636432, 18.545427271363568]\n",
       "african   [43, 39]           4   [23.51057552877644, 58.48942447122356]\n",
       "process   [16, 12]           4  [8.028001400070004, 19.971998599929996]\n",
       "relative  [13, 10]           3  [6.594429721486074, 16.405570278513927]\n",
       "marine     [12, 9]           3  [6.021001050052503, 14.978998949947497]\n",
       "plants     [12, 9]           3  [6.021001050052503, 14.978998949947497]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producing the chisquare values again, this time for `observed_expected_2`, and the respective p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chisquare value</th>\n",
       "      <th>p-value</th>\n",
       "      <th>over 5% threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>41.925086</td>\n",
       "      <td>9.483806e-11</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>painter</th>\n",
       "      <td>15.524748</td>\n",
       "      <td>8.143213e-05</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>13.733503</td>\n",
       "      <td>2.106630e-04</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spirit</th>\n",
       "      <td>11.341071</td>\n",
       "      <td>7.581159e-04</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>11.341071</td>\n",
       "      <td>7.581159e-04</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liquid</th>\n",
       "      <td>12.719123</td>\n",
       "      <td>3.619354e-04</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulitzer</th>\n",
       "      <td>10.707336</td>\n",
       "      <td>1.067116e-03</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>african</th>\n",
       "      <td>22.650160</td>\n",
       "      <td>1.943440e-06</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>11.098480</td>\n",
       "      <td>8.639852e-04</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>8.723181</td>\n",
       "      <td>3.141895e-03</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marine</th>\n",
       "      <td>8.323860</td>\n",
       "      <td>3.912769e-03</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plants</th>\n",
       "      <td>8.323860</td>\n",
       "      <td>3.912769e-03</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          chisquare value       p-value over 5% threshold\n",
       "term                                                     \n",
       "monitor         41.925086  9.483806e-11                no\n",
       "painter         15.524748  8.143213e-05                no\n",
       "example         13.733503  2.106630e-04                no\n",
       "spirit          11.341071  7.581159e-04                no\n",
       "andrew          11.341071  7.581159e-04                no\n",
       "liquid          12.719123  3.619354e-04                no\n",
       "pulitzer        10.707336  1.067116e-03                no\n",
       "african         22.650160  1.943440e-06                no\n",
       "process         11.098480  8.639852e-04                no\n",
       "relative         8.723181  3.141895e-03                no\n",
       "marine           8.323860  3.912769e-03                no\n",
       "plants           8.323860  3.912769e-03                no"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared_2 = []\n",
    "\n",
    "for index, series in observed_expected_2.iterrows():\n",
    "    \n",
    "    obs = series[0]\n",
    "    exp = series[2]\n",
    "\n",
    "    chisquare_value, pvalue  = chisquare(obs, exp)\n",
    "    \n",
    "    chi_squared_2.append([chisquare_value, pvalue])\n",
    "    \n",
    "chi_squared_df_2 = pd.DataFrame(chi_squared_2,\n",
    "                                columns=['chisquare value', 'p-value'],\n",
    "                                index=observed_expected_2.index).rename_axis('term')\n",
    "\n",
    "chi_squared_df_2['over 5% threshold'] = chi_squared_df_2['p-value'].apply(lambda x: 'yes' if x > 0.05 else 'no')\n",
    "\n",
    "chi_squared_df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "\n",
    "The original idea is to find out, from a randomly chosen set of terms/topics, which ones are more likely to be used in high value questions. First of all, we know that every term in this short list has appeared more often in high value questions than in low value questions. Also, we can tell that for all terms, the p-value is near zero, which means that we can reject the (null) hypothesis, that tells us that the given distribution of the term, where there are more high value questions than low value questions, is unlikely to be found on a random draw, where the probability of drawing a high value or a low value question is equally distributed (50% chance). In other words, this means that there is some evidence that these distributions are not random, so that we can at least try to pick some subjects to study, based on these terms, because we know that by default, they are likely to be included more often in high value questions, than in low value questions. Looking at the list of terms, which is very short, some of them seem to be generic without a context; others, are indicative of certain subjects, e.g. 'pulitzer' (Journalism/Literature), 'painter' (History/Historical Figures)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra exercise: replicate the chi-squared test p-values 'manually'.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- We perform a 1000 rounds of filling out a series with the same length of jeopardy, 20000 rows, with values from 0 to 1. Because we are analyzing the possibility of each value to be 'high' or 'low' in 'nature', then we attribute the probability of drawing one of the values equally: 0.5. If we had 'high', 'medium', 'low', we would attribute equally 1/3 of drawing probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random   \n",
    "\n",
    "p_values = []\n",
    "\n",
    "for index, val in enumerate(chi_squared_df_2['chisquare value']):\n",
    "\n",
    "    chi_squared_values = []\n",
    "\n",
    "    for i in range(1000):\n",
    "        rand_series = np.random.random((jeopardy.shape[0],))\n",
    "        high = rand_series[rand_series >= 0.5].size\n",
    "        low = rand_series[rand_series < 0.5].size\n",
    "        high_diff = proportion_diff_sq(high, jeopardy.shape[0]/2)\n",
    "        low_diff = proportion_diff_sq(low, jeopardy.shape[0]/2)\n",
    "        chi_square = high_diff + low_diff\n",
    "        chi_squared_values.append(chi_square)\n",
    "\n",
    "    over_chisquare_term = [chi for chi in chi_squared_values if \\\n",
    "                           chi >= val]\n",
    "\n",
    "    p_value = len(over_chisquare_term) / 1000\n",
    "\n",
    "    p_values.append(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below, the 'manually' produced p-values are almost identical to the ones previously computed with the 'scipy' library, being all near zero, thus confirming the same conclusions already withdrawn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scipy p-value</th>\n",
       "      <th>manual p-value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>9.483806e-11</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>painter</th>\n",
       "      <td>8.143213e-05</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>2.106630e-04</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spirit</th>\n",
       "      <td>7.581159e-04</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>7.581159e-04</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liquid</th>\n",
       "      <td>3.619354e-04</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulitzer</th>\n",
       "      <td>1.067116e-03</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>african</th>\n",
       "      <td>1.943440e-06</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>8.639852e-04</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>3.141895e-03</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marine</th>\n",
       "      <td>3.912769e-03</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plants</th>\n",
       "      <td>3.912769e-03</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          scipy p-value  manual p-value\n",
       "term                                   \n",
       "monitor    9.483806e-11           0.000\n",
       "painter    8.143213e-05           0.000\n",
       "example    2.106630e-04           0.000\n",
       "spirit     7.581159e-04           0.001\n",
       "andrew     7.581159e-04           0.001\n",
       "liquid     3.619354e-04           0.002\n",
       "pulitzer   1.067116e-03           0.000\n",
       "african    1.943440e-06           0.000\n",
       "process    8.639852e-04           0.001\n",
       "relative   3.141895e-03           0.006\n",
       "marine     3.912769e-03           0.003\n",
       "plants     3.912769e-03           0.003"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values_comp = pd.DataFrame({'scipy p-value': chi_squared_df_2['p-value'], 'manual p-value': p_values})\n",
    "\n",
    "p_values_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide 8\n",
    "---\n",
    "That's it for the guided steps! We recommend you explore the data more.\n",
    "\n",
    "Here are some potential next steps:\n",
    "\n",
    "- Find a better way to eliminate non-informative words than just removing words that are less than 6 characters long. Some ideas:\n",
    "    - Manually create a list of words to remove, like the, than, etc.\n",
    "    - Find a list of stopwords to remove.\n",
    "    - Remove words that occur in more than a certain percentage (like 5%) of questions.\n",
    "    \n",
    "    \n",
    "- Perform the chi-squared test across more terms to see what terms have larger differences. This is hard to do currently because the code is slow, but here are some ideas:\n",
    "    - Use the apply method to make the code that calculates frequencies more efficient.\n",
    "    - Only select terms that have high frequencies across the dataset, and ignore the others.\n",
    "    \n",
    "    \n",
    "- Look more into the Category column and see if any interesting analysis can be done with it. Some ideas:\n",
    "    - See which categories appear the most often.\n",
    "    - Find the probability of each category appearing in each round.\n",
    "    \n",
    "    \n",
    "- ~~Use the whole Jeopardy dataset (available here) instead of the subset we used in this lesson.~~\n",
    "\n",
    "\n",
    "- Use phrases instead of single words when seeing if there's overlap between questions. Single words don't capture the whole context of the question well.\n",
    "\n",
    "\n",
    "We recommend creating a Github repository and placing this project there. It will help other people, including employers, see your work. As you start to put multiple projects on Github, you'll have the beginnings of a strong portfolio.\n",
    "\n",
    "You're welcome to keep working on the project here, but we recommend downloading it to your computer using the download icon above and working on it there.\n",
    "\n",
    "Curious to see what other students have done on this project? Head over to our Community to check them out. While you are there, please remember to share your experience and provide feedback!\n",
    "\n",
    "In addition, we welcome you to share your own project and show off your hard work. Head over to our Community to share your finished Guided Project!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "458px",
    "width": "360px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "236.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "398.017px",
    "left": "1384.83px",
    "right": "20px",
    "top": "120px",
    "width": "355.167px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
