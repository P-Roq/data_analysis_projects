{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy - How To Set A Winning Strategy Based On The Insights Provided By Records Of Old Questions And Answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "---\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money [source: Dataquest]. In this project we explore a sample of 20000 (out of 216930) questions and respective answers, originally compiled by a [reddit user](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/), and try to figure out ways of maximizing the earnings by looking for patterns in the data. Two of the questions we'll try to explore are:\n",
    "\n",
    "- How often an answer can be used to formulate a question.\n",
    "\n",
    "- How often questions repeat.\n",
    "\n",
    "\n",
    "The description of every column in the data set:\n",
    "\n",
    "| Name | Description |\n",
    "| ----------- | -------------------------------------------------- |\n",
    "| Show Number | Jeopardy episode number.                       |\n",
    "| Air Date    | Date the episode aired.                        |\n",
    "| Round       | Round of Jeopardy.                             |\n",
    "| Category    | Category of the question.                      |\n",
    "| Value       | Number of dollars the correct answer is worth. |\n",
    "| Question    | Text of the question.                          |\n",
    "| Answer      | Text of the answer.                            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A First Look Into The Data Set\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "init_cell": true,
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy = pd.read_csv('jeopardy.csv', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Show Number  19999 non-null  int64 \n",
      " 1   Air Date     19999 non-null  object\n",
      " 2   Round        19999 non-null  object\n",
      " 3   Category     19999 non-null  object\n",
      " 4   Value        19999 non-null  object\n",
      " 5   Question     19999 non-null  object\n",
      " 6   Answer       19999 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "---\n",
    "\n",
    "### Normalizing Questions And Answers (Text Columns)\n",
    "\n",
    "In order to make elements in the `Questions` column comparable to those in the `Answers` column, I make a small normalization process for the two columns: \n",
    "\n",
    "- applying a function that lowercases strings and removes punctuation.\n",
    "- assigning those changes to a pair of new columns: `clean_question` and `clean_answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_string(string):\n",
    "    \"\"\"Takes in a string and lowercases it and removes punctuation.\"\"\"\n",
    "    \n",
    "    string_mod = str.lower(string)\n",
    "    string_mod = re.sub('\\W', ' ', string_mod)\n",
    "    \n",
    "    return string_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = jeopardy['Question'].apply(norm_string)\n",
    "\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(norm_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing two consecutive or more whitespaces into one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = \\\n",
    "    jeopardy['clean_question'].str.replace('\\s{2,}', ' ', regex=True)\n",
    "\n",
    "jeopardy['clean_answer'] = \\\n",
    "    jeopardy['clean_answer'].str.replace('\\s{2,}', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Data Cleaning (Numeric Columns)\n",
    "\n",
    "\n",
    "- Transform values in the `Value` column into integers.\n",
    "- Transform values in `Air Date` into _datetime_ values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, a function to be applied on `Value` to turn the values into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_usd(string):\n",
    "    \"\"\"Converts a string/currency value into an integer.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        converted = re.sub('(\\$|,)', '', string)\n",
    "        converted = int(converted)\n",
    "    except:\n",
    "        converted = 0\n",
    "    \n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_value'] = jeopardy['Value'].apply(norm_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  200,   400,   600,   800,  2000,  1000,  1200,  1600,  3200,\n",
       "           0,  5000,   100,   300,   500,  1500,  4800,  1800,  1100,\n",
       "        2200,  3400,  3000,  4000,  6800,  1900,  3100,   700,  1400,\n",
       "        2800,  8000,  6000,  2400, 12000,  3800,  2500,  6200, 10000,\n",
       "        7000,  1492,  7400,  1300,  7200,  2600,  3300,  5400,  4500,\n",
       "        2100,   900,  3600,  2127,   367,  4400,  3500,  2900,  3900,\n",
       "        4100,  4600, 10800,  2300,  5600,  1111,  8200,  5800,   750,\n",
       "        7500,  1700,  9000,  6100,  1020,  4700,  2021,  5200,  3389])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['clean_value'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the column 'Air Date' can be converted to a datetime type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_air_date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Often The Answer Can Be Used For A Question?\n",
    "---\n",
    "\n",
    "If a participant, out of bad luck,  were to be totally clueless about the questions being directed at her/him during the show, could the participant resort to the question to pull out the answer? In other words, how many times can a participant find words in the question that can be also be found in the answer? The extreme version of this would be the famous joke phrase - 'What's the color of napoleon's white horse?' (Answer: 'white').\n",
    "\n",
    "A way to check this is to go row by row, comparing question and respective answer, and calculate the proportion of words in the answer given the total number of words in the question. `count_matches()` is a function that does just that. Note that the very common word 'the' is taken from the answer since has no relevancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(row):\n",
    "    \n",
    "    split_answer = row[\"clean_answer\"].split(' ')\n",
    "    split_question = row[\"clean_question\"].split(' ')\n",
    "    \n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\") # removing 'the' as common word\n",
    "        \n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    \n",
    "    match_count = 0\n",
    "    \n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "            \n",
    "    return match_count / len(split_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(count_matches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'answer_in_question_mean = 6.93%'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_in_question_mean = round(jeopardy[\"answer_in_question\"].mean()*100, 2) \n",
    "\n",
    "f'{answer_in_question_mean = }%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, only about 7% of the words in the question are also in the answer. This likely means that more often than not, question and associated answer can share other common words besides 'the', such as 'a', 'an', 'for', 'in', etc (see examples of a slice of cleaned answers below),\n",
    "hence frustrating the strategy of resorting to the words in the questions alone, to find the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20                                              morocco\n",
       "21                                          paul bonwit\n",
       "22    hattie mcdaniel for her role in gone with the ...\n",
       "23                                                  era\n",
       "24                                   the congress party\n",
       "25                                     wilt chamberlain\n",
       "26                                                   k2\n",
       "27                                          ethan allen\n",
       "28                                                  ply\n",
       "29                                               horton\n",
       "30                                                nixon\n",
       "31                                             a kennel\n",
       "32                                                moses\n",
       "33                                            aerosmith\n",
       "34                                              oratory\n",
       "35                          coolidge or chester arthur \n",
       "36                                       business class\n",
       "37                                             muhammed\n",
       "38                                   the mystery train \n",
       "39                                     an old fashioned\n",
       "40                                               yertle\n",
       "Name: clean_answer, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.loc[20:40,'clean_answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering The Question - 'How Often Questions Are Repeated', By Seeing How Often Complex Words Reoccur\n",
    "---\n",
    "\n",
    "This task takes on a similar approach to the previous one, but in this case, instead of comparing words in the question against the the ones in the answer, it compares the words in the question against a pool of words saved from previous questions; if we find repeated words in that process, we take the ratio of repeated words (from previous questions) vs the total number of words in the question, and later on, average out the list of ratios. \n",
    "\n",
    "In order to exclude common words, we only identify expressions with more complexity - words with more than 5 characters. In theory, this should allow to make this type of inference: if a complex word was used already in a previous question and has appeared again, then, in the context of this new question, it must be asking the same thing as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary Clean-up: Ordering Questions By Show Air Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy = jeopardy.sort_values(by='Air Date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process below, Stage 2 (marked as a comment) is divided into two loops - 'a' and 'b', so that we can register repeated words among questions/rows and thus avoid counting repeated words within the same question as re-occurrences. Mind as well that there is a time logic behind this process, hence the questions being sorted by air date: occurrences only happen when we compare one question with questions that appeared in past shows (or in the same air date). \n",
    "\n",
    "Moreover on the order of the question by air date: we don't have a way of ordering the questions if they have the same air date - which one was asked first during the show?, we don't have time references or other method to determine that, therefore, we take the order produced by `df.sort_values()` as is.\n",
    "\n",
    "Sets (Python Object) can form random orders each time they are created, even if they have the same content. Therefore, it is better to perform the loop process once, in order to fill out `terms_used` with the desired terms, convert it into a list, and save it externally, so that we can preserve the order of the values. Since `question_overlap` is derived from `terms_used`, we store it as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_1 = 1\n",
    "\n",
    "if runs_1 == 0: \n",
    "    \n",
    "    runs_1 += 1 \n",
    "    \n",
    "    question_overlap = []\n",
    "\n",
    "    terms_used = set()\n",
    "\n",
    "    for index, val in enumerate(jeopardy['clean_question']):\n",
    "\n",
    "        ## Stage 1.\n",
    "        split_question = val.split(' ')\n",
    "\n",
    "        split_question = [word for word in split_question if len(word) >= 6]\n",
    "\n",
    "\n",
    "        ## Stage 2.\n",
    "        match_count = 0\n",
    "\n",
    "        # Loop a.\n",
    "        for word in split_question:\n",
    "            if word in terms_used:\n",
    "                match_count += 1\n",
    "\n",
    "        # Loop b.\n",
    "        for word in split_question:\n",
    "            terms_used.add(word)\n",
    "\n",
    "\n",
    "        ## Stage 3. \n",
    "        if len(split_question):\n",
    "            match_count /= len(split_question)\n",
    "\n",
    "        question_overlap.append(match_count)\n",
    "\n",
    "\n",
    "    # Saving `question_overlap` and `terms_used` into pickle files.\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    # Creating a binary pickle file for each object.\n",
    "    qo = open(\"question_overlap.pkl\",\"wb\") \n",
    "    tu = open(\"terms_used.pkl\",\"wb\") \n",
    "\n",
    "    # Write the python object to pickle file.\n",
    "    pickle.dump(question_overlap, qo)\n",
    "    pickle.dump(list(terms_used), tu) # converted into a list before saving\n",
    "\n",
    "    # close file\n",
    "    qo.close()\n",
    "    tu.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the objects back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'question_overlap' not in locals():\n",
    "\n",
    "    question_overlap = pd.read_pickle(\"question_overlap.pkl\") # original object overwritten \n",
    "\n",
    "    terms_used_list = pd.read_pickle(\"terms_used.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally producing the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question_overlap_mean = 71.98%'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['question_overlap'] = pd.Series(question_overlap)  \n",
    "\n",
    "question_overlap_mean = jeopardy['question_overlap'].mean()\n",
    "\n",
    "question_overlap_mean = round(question_overlap_mean*100, 2)\n",
    "\n",
    "f'{question_overlap_mean = }%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment: interpretation of the result and discussion.\n",
    "\n",
    "The value above suggests that, on average, aprox. 72% of the words used in a question were already used in a previous similar question. Although neatly conveyed in a single measurement, the validity of the previous method as a mean capable of identifying repeated questions can be skeptically questioned. First, resorting to a bank of repeated words to determine which words in a given question are also repeated may not be very useful, since the same words may be used to formulate different questions. Also, computing the ratio of repeated words of a question in relation to the total number of words does not make great sense; by definition, categorizing a question as repeated entails that a previous question, which had the same context, was also answered similarly (in this case we seek identical answers). We are looking for a binary situation such as: 'is this question a repeated one or not?'; we should not seek to answer: 'this question is 75% repeated' because three out of four words were used randomly (i.e. in various possible contexts) in past questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Target Highly Paid Questions By Inferring Their Most Common Themes\n",
    "---\n",
    "From Dataquest's tutorial:\n",
    "\n",
    "\n",
    ">Let's say you only want to study questions that pertain to high value questions instead of low value questions. This will help you earn more money when you're on Jeopardy.\n",
    ">\n",
    ">You can actually figure out which terms correspond to high-value questions using a chi-squared test. You'll first need to narrow down the questions into two categories:\n",
    ">\n",
    ">- Low value -- Any row where `Value` is less than `800`.\n",
    ">- High value -- Any row where `Value` is greater than `800`.\n",
    ">\n",
    ">You'll then be able to loop through each of the terms from the last screen, `terms_used`, and:\n",
    ">\n",
    ">\n",
    ">- Find the number of low value questions the word occurs in.\n",
    ">\n",
    ">\n",
    ">- Find the number of high value questions the word occurs in.\n",
    ">\n",
    ">\n",
    ">- Find the percentage of questions the word occurs in.\n",
    ">\n",
    ">\n",
    ">- Based on the percentage of questions the word occurs in, find expected counts.\n",
    ">\n",
    ">\n",
    ">- Compute the chi squared value based on the expected counts and the observed counts for high and low value questions.\n",
    ">\n",
    ">You can then find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. Doing this for all of the words would take a very long time, so we'll just do it for a small sample now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: 'Pre-arrange The Data Set, Pick 10 Words/Subjects And Find Their Observed Values In High Value Questions And Low Value Questions.'\n",
    "\n",
    "\n",
    "The process goes through the following steps:\n",
    "\n",
    "1. creating a new column that defines each question/row as 'high value' or 'low_value'. \n",
    "2. picking randomly 10 terms from the `terms_used` pool.\n",
    "3. building the function that counts, for each term chosen in Step 2, the number of high value and low value questions that contain that expression (a least once).\n",
    "4. the output generated in Step 3 is saved in a Series called `observed`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. classify each question/row as high value or low value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_value</th>\n",
       "      <th>high_or_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>800</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1900</td>\n",
       "      <td>high_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>800</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1000</td>\n",
       "      <td>high_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1000</td>\n",
       "      <td>high_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>400</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1000</td>\n",
       "      <td>high_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>400</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>400</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>400</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>100</td>\n",
       "      <td>low_value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clean_value high_or_low\n",
       "80          800   low_value\n",
       "81         1900  high_value\n",
       "82          800   low_value\n",
       "83         1000  high_value\n",
       "84         1000  high_value\n",
       "85          400   low_value\n",
       "86         1000  high_value\n",
       "87          400   low_value\n",
       "88          400   low_value\n",
       "89          400   low_value\n",
       "90          100   low_value"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['high_or_low'] = jeopardy['clean_value'].apply(lambda x: 'high_value' if x > 800 else 'low_value')\n",
    "\n",
    "# Checking new column, random slice.\n",
    "jeopardy.loc[80:90, ['clean_value', 'high_or_low']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. randomly pick 10 terms from `terms_used` and save them into a list - `comparison_term` (only done once); output saved in the list below to prevent overwriting it when re-running the notebook.\n",
    "\n",
    "        import random\n",
    "\n",
    "\n",
    "        comparison_term = random.sample(terms_used_list), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_term = [\n",
    "    'coronado',\n",
    "    'residence',\n",
    "    'subatomic',\n",
    "    'halston',\n",
    "    'nuremberg',\n",
    "    'plumber',\n",
    "    'osment',\n",
    "    'tortured',\n",
    "    'relatively',\n",
    "    'herradura'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. build the function that counts how many high value and low value questions contain each one of the terms in `comparison_term`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_highs_and_lows(word):\n",
    "    \"\"\"Takes a word and returns how many times that word was used in high value questions\n",
    "    and low value questions.\n",
    "    \"\"\"\n",
    "    \n",
    "    high_counts = 0\n",
    "    low_counts = 0\n",
    "    \n",
    "    for i, val in enumerate(jeopardy['clean_question']):\n",
    "        \n",
    "        split = val.split(' ')\n",
    "        \n",
    "        if word in split:\n",
    "            if jeopardy.loc[i, 'high_or_low'] == 'high_value':\n",
    "                high_counts += 1\n",
    "            else:\n",
    "                low_counts += 1\n",
    "\n",
    "    return [high_counts, low_counts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. apply `count_highs_and_lows()` function and display results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 0]\n",
       "1    [4, 4]\n",
       "2    [1, 1]\n",
       "3    [0, 1]\n",
       "4    [1, 0]\n",
       "5    [1, 1]\n",
       "6    [1, 0]\n",
       "7    [0, 1]\n",
       "8    [0, 3]\n",
       "9    [0, 1]\n",
       "Name: observed, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_list = [count_highs_and_lows(word) for word in comparison_term]\n",
    "\n",
    "observed = pd.Series(observed_list, name='observed')\n",
    "\n",
    "observed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate The Respective Expected Values\n",
    "\n",
    "Counting number of high value questions and low value questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high_value_count = 5734\n",
      "low_value_count = 14265\n"
     ]
    }
   ],
   "source": [
    "high_value_count = jeopardy[jeopardy['high_or_low']=='high_value'].shape[0]\n",
    "\n",
    "low_value_count = jeopardy[jeopardy['high_or_low']!='high_value'].shape[0]\n",
    "\n",
    "# checking counts:\n",
    "print(f'{high_value_count = }', f'{low_value_count = }', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing expected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.28671433571678584, 0.7132856642832142]\n",
       "1      [2.2937146857342867, 5.706285314265713]\n",
       "2     [0.5734286714335717, 1.4265713285664283]\n",
       "3    [0.28671433571678584, 0.7132856642832142]\n",
       "4    [0.28671433571678584, 0.7132856642832142]\n",
       "5     [0.5734286714335717, 1.4265713285664283]\n",
       "6    [0.28671433571678584, 0.7132856642832142]\n",
       "7    [0.28671433571678584, 0.7132856642832142]\n",
       "8     [0.8601430071503575, 2.1398569928496425]\n",
       "9    [0.28671433571678584, 0.7132856642832142]\n",
       "Name: expected, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected = []\n",
    "\n",
    "for i, val in enumerate(observed):\n",
    "    \n",
    "    # High and Low value count.\n",
    "    high_count = val[0]\n",
    "    low_count = val[1]\n",
    "    \n",
    "    # Proportion of words vs total number of questions\n",
    "    total_prop = (high_count + low_count) / jeopardy.shape[0]\n",
    "    \n",
    "    expected_high = total_prop * high_value_count\n",
    "    expected_low = total_prop * low_value_count\n",
    "    \n",
    "    expected.append([expected_high, expected_low])\n",
    "    \n",
    "expected = pd.Series(expected, name='expected')\n",
    "\n",
    "expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Observed And Expected Values Into A DataFrame And Produce Chi-square Test Results For Each Word/Row\n",
    "\n",
    "Putting observed and expected values into a DataFrame: `observed_expected`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coronado</th>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.28671433571678584, 0.7132856642832142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residence</th>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>[2.2937146857342867, 5.706285314265713]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subatomic</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.5734286714335717, 1.4265713285664283]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>halston</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.28671433571678584, 0.7132856642832142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuremberg</th>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.28671433571678584, 0.7132856642832142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plumber</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.5734286714335717, 1.4265713285664283]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osment</th>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.28671433571678584, 0.7132856642832142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tortured</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.28671433571678584, 0.7132856642832142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relatively</th>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>[0.8601430071503575, 2.1398569928496425]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herradura</th>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.28671433571678584, 0.7132856642832142]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           observed                                   expected\n",
       "coronado     [1, 0]  [0.28671433571678584, 0.7132856642832142]\n",
       "residence    [4, 4]    [2.2937146857342867, 5.706285314265713]\n",
       "subatomic    [1, 1]   [0.5734286714335717, 1.4265713285664283]\n",
       "halston      [0, 1]  [0.28671433571678584, 0.7132856642832142]\n",
       "nuremberg    [1, 0]  [0.28671433571678584, 0.7132856642832142]\n",
       "plumber      [1, 1]   [0.5734286714335717, 1.4265713285664283]\n",
       "osment       [1, 0]  [0.28671433571678584, 0.7132856642832142]\n",
       "tortured     [0, 1]  [0.28671433571678584, 0.7132856642832142]\n",
       "relatively   [0, 3]   [0.8601430071503575, 2.1398569928496425]\n",
       "herradura    [0, 1]  [0.28671433571678584, 0.7132856642832142]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected = pd.concat([observed, expected], axis=1)\n",
    "\n",
    "observed_expected.index = comparison_term\n",
    "\n",
    "observed_expected "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producing the chi-square tests and associated p-values for every term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chi-square value</th>\n",
       "      <th>p-value</th>\n",
       "      <th>over 5% threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coronado</th>\n",
       "      <td>2.487792</td>\n",
       "      <td>0.114733</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuremberg</th>\n",
       "      <td>2.487792</td>\n",
       "      <td>0.114733</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osment</th>\n",
       "      <td>2.487792</td>\n",
       "      <td>0.114733</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residence</th>\n",
       "      <td>1.779510</td>\n",
       "      <td>0.182210</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relatively</th>\n",
       "      <td>1.205889</td>\n",
       "      <td>0.272148</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subatomic</th>\n",
       "      <td>0.444877</td>\n",
       "      <td>0.504778</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plumber</th>\n",
       "      <td>0.444877</td>\n",
       "      <td>0.504778</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>halston</th>\n",
       "      <td>0.401963</td>\n",
       "      <td>0.526077</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tortured</th>\n",
       "      <td>0.401963</td>\n",
       "      <td>0.526077</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herradura</th>\n",
       "      <td>0.401963</td>\n",
       "      <td>0.526077</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            chi-square value   p-value over 5% threshold\n",
       "term                                                    \n",
       "coronado            2.487792  0.114733               yes\n",
       "nuremberg           2.487792  0.114733               yes\n",
       "osment              2.487792  0.114733               yes\n",
       "residence           1.779510  0.182210               yes\n",
       "relatively          1.205889  0.272148               yes\n",
       "subatomic           0.444877  0.504778               yes\n",
       "plumber             0.444877  0.504778               yes\n",
       "halston             0.401963  0.526077               yes\n",
       "tortured            0.401963  0.526077               yes\n",
       "herradura           0.401963  0.526077               yes"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare \n",
    "\n",
    "chi_squared = []\n",
    "\n",
    "for index, series in observed_expected.iterrows():\n",
    "    \n",
    "    obs = series[0]\n",
    "    exp = series[1]\n",
    "\n",
    "    chisquare_value, pvalue  = chisquare(obs, exp)\n",
    "    \n",
    "    chi_squared.append([chisquare_value, pvalue])\n",
    "    \n",
    "chi_squared_df = pd.DataFrame(chi_squared,\n",
    "                              columns=['chi-square value', 'p-value'],\n",
    "                              index=comparison_term).rename_axis('term')\n",
    "\n",
    "chi_squared_df['over 5% threshold'] = chi_squared_df['p-value'].apply(lambda x: 'yes' if x > 0.05 else 'no')\n",
    "\n",
    "chi_squared_df.sort_values('chi-square value', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the random sample taken from the pool of terms, `chi_squared_df` shows that all the p-values are over the 5% threshold, therefore we cannot reject the null hypothesis that there is no unequal distribution between the number of high value and low value questions for these terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing themes/terms based on the validation of the chisquare value\n",
    "\n",
    "\n",
    "Following the tutorial's instructions leads us to a major problem that invalidates the tests' results shown above in `chi_squared_df`. The problem stems from the fact that, when sampling for complex words (terms), we are not taking into account that questions with such terms have extremely low observed counts. From the [scipy documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html):\n",
    "\n",
    "\n",
    ">This test is invalid when the observed or expected frequencies in each category are too small. A typical rule is that all of the observed and expected frequencies should be at least 5. According to [3], the total number of samples is recommended to be greater than 13, otherwise exact tests (such as Barnardâ€™s Exact test) should be used because they do not overreject.\n",
    "\n",
    "Also, simply looking at the chi-square value magnitude is not enough to determine whether a term is more likely to be occurring in high value questions since the squared proportion difference of low value questions may be the component that inflates the chi-square value. Recall the chi-square value for the present scenario:\n",
    "\n",
    "\\begin{equation}\n",
    "\\chi^{2} = \\frac{(\\text{high value obs} - \\text{high value exp})^2}{\\text{high value exp}} + \n",
    "       \\frac{(\\text{low value obs} - \\text{low value exp})^2}{\\text{low value exp}}  \n",
    "\\end{equation}\n",
    "\n",
    "Despite of the tests being invalid, for practicing purposes, reading them as is, would indicate that 'none of the terms had a significant difference in usage between high value and low value rows' (from the [solution notebook]((https://github.com/dataquestio/solutions/blob/master/Mission210Solution.ipynb)), which finds similar results).\n",
    "\n",
    "\n",
    "Furthermore, from a single term alone, is difficult to assess the overall context in which its being used, e.g. if we can infer that History of World War II is a recurrent topic because of the term 'nuremberg' as in 'Nuremberg Trials', not much can be said about what subjects, 'residence' or 'relatively', are alluding to. \n",
    "\n",
    "\n",
    "\n",
    "Regarding the chi-square test, two immediate improvements can be made:\n",
    "\n",
    " - a) consider only terms that can be found more often in high value questions than in low value questions. To this end, we can make a chain of procedures:\n",
    "    1. calculate for every term the difference between (observed) high value and low value questions counts.\n",
    "    2. sort terms/rows, in descending order, based on the magnitude of the differences in counts calculated in Step 1.\n",
    "    3. drop all rows when the difference between high and low count is not positive (we only are interested in terms that appear more often in high value than low value questions).\n",
    "    4. slice the DataFrame, so that it only contains the top 100 terms which have the greatest differences.\n",
    "    5. compute the expected values for each term/row.\n",
    "\n",
    "\n",
    " - b) from the final output produced in a), filter that DataFrame, selecting only the terms that have observed and expected values over 5. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Starting with a):\n",
    "\n",
    "- Since we are computing the observed values for 21223 terms, we apply the function `count_highs_and_lows()` for each row in `terms_used_series`  once and save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_2 = 1\n",
    "\n",
    "if runs_2 == 0:\n",
    "    \n",
    "    runs_2 += 1\n",
    "\n",
    "    terms_used_series = pd.Series(terms_used_list) \n",
    "\n",
    "    observed_2 = terms_used_series.apply(count_highs_and_lows) \n",
    "\n",
    "    # Resorting to the pickle library again to save the `observed_2` output.\n",
    "    obsr_2 = open(\"observed_2.pkl\",\"wb\") \n",
    "\n",
    "    pickle.dump(observed_2, obsr_2)\n",
    "\n",
    "    obsr_2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading back and displaying the first rows in `observed_2_df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>croatia</th>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campuses</th>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accumulate</th>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voyages</th>\n",
       "      <td>[0, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emeritus</th>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           observed\n",
       "croatia      [2, 3]\n",
       "campuses     [1, 1]\n",
       "accumulate   [1, 0]\n",
       "voyages      [0, 3]\n",
       "emeritus     [1, 0]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_2_series = pd.read_pickle('observed_2.pkl')\n",
    "\n",
    "observed_2_df = pd.DataFrame(data={'observed': observed_2_series}).set_index(np.array(terms_used_list))\n",
    "\n",
    "observed_2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we compute the difference between high value and low value counts for each term/row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_2_df['difference'] = observed_2_df.observed.apply(lambda x: x[0] - x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>[37, 17]</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>painter</th>\n",
       "      <td>[17, 10]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>[16, 10]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>largely</th>\n",
       "      <td>[5, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creates</th>\n",
       "      <td>[6, 1]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hormone</th>\n",
       "      <td>[8, 3]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spirit</th>\n",
       "      <td>[13, 8]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orator</th>\n",
       "      <td>[8, 3]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>[13, 8]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyphenated</th>\n",
       "      <td>[8, 3]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            observed  difference\n",
       "monitor     [37, 17]          20\n",
       "painter     [17, 10]           7\n",
       "example     [16, 10]           6\n",
       "largely       [5, 0]           5\n",
       "creates       [6, 1]           5\n",
       "hormone       [8, 3]           5\n",
       "spirit       [13, 8]           5\n",
       "orator        [8, 3]           5\n",
       "andrew       [13, 8]           5\n",
       "hyphenated    [8, 3]           5"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_2_df_sorted = observed_2_df.sort_values('difference', ascending=False)\n",
    "\n",
    "observed_2_df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only terms with positive differences - 'high value' counts higher than 'low value' counts, and also keep only the top 100 terms that have the greatest difference between counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>[37, 17]</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>painter</th>\n",
       "      <td>[17, 10]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>[16, 10]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>largely</th>\n",
       "      <td>[5, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creates</th>\n",
       "      <td>[6, 1]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         observed  difference\n",
       "monitor  [37, 17]          20\n",
       "painter  [17, 10]           7\n",
       "example  [16, 10]           6\n",
       "largely    [5, 0]           5\n",
       "creates    [6, 1]           5"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_over_0 = observed_2_df_sorted[observed_2_df_sorted.difference > 0]\n",
    "\n",
    "difference_top_100 = difference_over_0.head(100).copy()\n",
    "\n",
    "difference_top_100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the expected high and low counts applying the function `find_expected()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_expected(observed_list):\n",
    "\n",
    "    # High and Low value count.\n",
    "    high_count = observed_list[0]\n",
    "    low_count = observed_list[1]\n",
    "\n",
    "    # Proportion of words vs total number of questions\n",
    "    total_prop = (high_count + low_count) / jeopardy.shape[0]\n",
    "\n",
    "    expected_high = total_prop * high_value_count\n",
    "    expected_low = total_prop * low_value_count\n",
    "\n",
    "    return [expected_high, expected_low]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of the transformation applied so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed</th>\n",
       "      <th>difference</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>[37, 17]</td>\n",
       "      <td>20</td>\n",
       "      <td>[15.482574128706435, 38.51742587129356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>painter</th>\n",
       "      <td>[17, 10]</td>\n",
       "      <td>7</td>\n",
       "      <td>[7.741287064353218, 19.25871293564678]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>[16, 10]</td>\n",
       "      <td>6</td>\n",
       "      <td>[7.454572728636432, 18.545427271363568]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>largely</th>\n",
       "      <td>[5, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.4335716785839292, 3.566428321416071]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creates</th>\n",
       "      <td>[6, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>[2.007000350017501, 4.992999649982499]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         observed  difference                                 expected\n",
       "monitor  [37, 17]          20  [15.482574128706435, 38.51742587129356]\n",
       "painter  [17, 10]           7   [7.741287064353218, 19.25871293564678]\n",
       "example  [16, 10]           6  [7.454572728636432, 18.545427271363568]\n",
       "largely    [5, 0]           5  [1.4335716785839292, 3.566428321416071]\n",
       "creates    [6, 1]           5   [2.007000350017501, 4.992999649982499]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_top_100['expected'] = difference_top_100['observed'].apply(find_expected)\n",
    "\n",
    "difference_top_100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task b)\n",
    "\n",
    "Creating a procedure to find out questions/rows that have both observed and expected values, high and low, equal or over 5, so that we can apply a valid chi-square test to each row.\n",
    "\n",
    "In the `df.iterrows()` process below, we go over the observed and expected values in each list (high and low value), and save the index value/term in `index_values_over_4`, whenever all those values are equal to 5 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_values_over_4 = []\n",
    "\n",
    "for index, series in difference_top_100.iterrows():\n",
    "    \n",
    "    # Example of `observed_expected`: [37, 17, 15.482574128706435, 38.51742587129356]\n",
    "    observed_expected = []\n",
    "    \n",
    "    observed_expected += series[0]\n",
    "    observed_expected += series[2]\n",
    "    \n",
    "    check_over_4 = [True for el in observed_expected if el >= 5]\n",
    "    \n",
    "    # Check_over_4 can only have 4 elements, [True, True, True, True], \n",
    "    # if all values in observed_expected are over 4. \n",
    "    if len(check_over_4) == 4:\n",
    "        index_values_over_4.append(series.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producing the final DataFrame for testing - `observed_expected_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12 entries, monitor to plants\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   observed    12 non-null     object\n",
      " 1   difference  12 non-null     int64 \n",
      " 2   expected    12 non-null     object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 384.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "observed_expected_2 = difference_top_100.loc[index_values_over_4, :]\n",
    "\n",
    "observed_expected_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed</th>\n",
       "      <th>difference</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>[37, 17]</td>\n",
       "      <td>20</td>\n",
       "      <td>[15.482574128706435, 38.51742587129356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>painter</th>\n",
       "      <td>[17, 10]</td>\n",
       "      <td>7</td>\n",
       "      <td>[7.741287064353218, 19.25871293564678]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>[16, 10]</td>\n",
       "      <td>6</td>\n",
       "      <td>[7.454572728636432, 18.545427271363568]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spirit</th>\n",
       "      <td>[13, 8]</td>\n",
       "      <td>5</td>\n",
       "      <td>[6.021001050052503, 14.978998949947497]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>[13, 8]</td>\n",
       "      <td>5</td>\n",
       "      <td>[6.021001050052503, 14.978998949947497]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liquid</th>\n",
       "      <td>[17, 12]</td>\n",
       "      <td>5</td>\n",
       "      <td>[8.31471573578679, 20.68528426421321]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulitzer</th>\n",
       "      <td>[15, 11]</td>\n",
       "      <td>4</td>\n",
       "      <td>[7.454572728636432, 18.545427271363568]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>african</th>\n",
       "      <td>[43, 39]</td>\n",
       "      <td>4</td>\n",
       "      <td>[23.51057552877644, 58.48942447122356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>[16, 12]</td>\n",
       "      <td>4</td>\n",
       "      <td>[8.028001400070004, 19.971998599929996]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>[13, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.594429721486074, 16.405570278513927]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marine</th>\n",
       "      <td>[12, 9]</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.021001050052503, 14.978998949947497]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plants</th>\n",
       "      <td>[12, 9]</td>\n",
       "      <td>3</td>\n",
       "      <td>[6.021001050052503, 14.978998949947497]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          observed  difference                                 expected\n",
       "monitor   [37, 17]          20  [15.482574128706435, 38.51742587129356]\n",
       "painter   [17, 10]           7   [7.741287064353218, 19.25871293564678]\n",
       "example   [16, 10]           6  [7.454572728636432, 18.545427271363568]\n",
       "spirit     [13, 8]           5  [6.021001050052503, 14.978998949947497]\n",
       "andrew     [13, 8]           5  [6.021001050052503, 14.978998949947497]\n",
       "liquid    [17, 12]           5    [8.31471573578679, 20.68528426421321]\n",
       "pulitzer  [15, 11]           4  [7.454572728636432, 18.545427271363568]\n",
       "african   [43, 39]           4   [23.51057552877644, 58.48942447122356]\n",
       "process   [16, 12]           4  [8.028001400070004, 19.971998599929996]\n",
       "relative  [13, 10]           3  [6.594429721486074, 16.405570278513927]\n",
       "marine     [12, 9]           3  [6.021001050052503, 14.978998949947497]\n",
       "plants     [12, 9]           3  [6.021001050052503, 14.978998949947497]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producing the chisquare values again, this time for `observed_expected_2`, and the respective p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chisquare_value</th>\n",
       "      <th>p-value</th>\n",
       "      <th>over 5% threshold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>41.925086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>african</th>\n",
       "      <td>22.650160</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>painter</th>\n",
       "      <td>15.524748</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>13.733503</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liquid</th>\n",
       "      <td>12.719123</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spirit</th>\n",
       "      <td>11.341071</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andrew</th>\n",
       "      <td>11.341071</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>11.098480</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pulitzer</th>\n",
       "      <td>10.707336</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>8.723181</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marine</th>\n",
       "      <td>8.323860</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plants</th>\n",
       "      <td>8.323860</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          chisquare_value   p-value over 5% threshold\n",
       "term                                                 \n",
       "monitor         41.925086  0.000000                no\n",
       "african         22.650160  0.000002                no\n",
       "painter         15.524748  0.000081                no\n",
       "example         13.733503  0.000211                no\n",
       "liquid          12.719123  0.000362                no\n",
       "spirit          11.341071  0.000758                no\n",
       "andrew          11.341071  0.000758                no\n",
       "process         11.098480  0.000864                no\n",
       "pulitzer        10.707336  0.001067                no\n",
       "relative         8.723181  0.003142                no\n",
       "marine           8.323860  0.003913                no\n",
       "plants           8.323860  0.003913                no"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared_2 = []\n",
    "\n",
    "for index, series in observed_expected_2.iterrows():\n",
    "    \n",
    "    obs = series[0]\n",
    "    exp = series[2]\n",
    "\n",
    "    chisquare_value, pvalue = chisquare(obs, exp)\n",
    "    \n",
    "    chi_squared_2.append([chisquare_value, pvalue])\n",
    "    \n",
    "chi_squared_df_2 = pd.DataFrame(chi_squared_2,\n",
    "                                columns=['chisquare_value', 'p-value'],\n",
    "                                index=observed_expected_2.index).rename_axis('term')\n",
    "\n",
    "chi_squared_df_2['over 5% threshold'] = chi_squared_df_2['p-value'].apply(lambda x: 'yes' if x > 0.05 else 'no')\n",
    "\n",
    "chi_squared_df_2['p-value'] = chi_squared_df_2['p-value'].round(6)\n",
    "\n",
    "chi_squared_df_2.sort_values('chisquare_value', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing `chi_squared_df_2` we can assume that there is some evidence that the distributions of these terms differ from a distribution based on random draws where the probability of drawing a high value or a low value question is equally distributed with a 50% chance (we can reject the null hypothesis in all cases, since all p-values are under the 5% threshold), so that we can at least try to pick some subjects to study, based on these terms, because we know that by default, they are likely to be included more often in high value questions than in low value questions. Looking at the list of terms, which is very short, we see that some of them seem to be generic, without a specific context; others, are indicative of certain subjects, e.g. 'pulitzer' (Journalism/Literature/Politics), 'painter' (Art/History/Historical Figures), plants (botany/biology).\n",
    "\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "---\n",
    "To conclude we can re-state the three major conclusion withdrawn from this analysis: i) words within a random question are unlikely to match the respective answer: on average, words in the answer constitute 7% of the total number of words in the respective question; ii) there is some evidence that questions with complex words (5 or more characters) have repetitions or similar questions, since on average, 72% of the words in one of those questions have been used previously; iii) to pursuit a game strategy of answering high value questions based on their themes, one can try to withdraw inspiration from the list of terms in `chi_squared_df_2`, since these terms are more likely to be associated with high value questions than low value.    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\[end of project\\]\n",
    "\n",
    "\\***"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "458px",
    "width": "360px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "298.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "398.017px",
    "left": "1384.83px",
    "right": "20px",
    "top": "120px",
    "width": "355.167px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
